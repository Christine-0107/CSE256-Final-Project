INFO 2024-04-09 15:30:34,181 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(196864, rest(789504)
INFO 2024-04-09 15:30:34,181 Check the whole parameters: 141525504 = 141525504
INFO 2024-04-09 15:32:46,644 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-09 15:32:48,070 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-09 15:32:48,100 The size of dataset: train(10492), test(2628)
INFO 2024-04-09 15:32:48,100 Start training
INFO 2024-04-09 15:42:00,804 iter:0, loss:3.229703187942505, total_2:2627, cnt_2:116, acc:81
INFO 2024-04-09 15:57:00,763 iter:1000, loss:1.6155143976211548, total_2:2627, cnt_2:116, acc:217
INFO 2024-04-09 16:12:09,186 iter:2000, loss:1.5790367126464844, total_2:2627, cnt_2:116, acc:222
INFO 2024-04-09 16:22:55,499 sss
INFO 2024-04-09 16:22:56,587 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-09 16:22:56,588 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpuqh6nhp_
INFO 2024-04-09 16:22:59,723 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-09 16:23:01,428 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(196864, rest(789504)
INFO 2024-04-09 16:23:01,428 Check the whole parameters: 141525504 = 141525504
INFO 2024-04-09 16:25:15,169 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-09 16:25:16,705 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-09 16:25:16,739 The size of dataset: train(34231), test(4926)
INFO 2024-04-09 16:25:16,739 Start training
INFO 2024-04-09 16:34:23,154 sss
INFO 2024-04-09 16:34:24,293 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-09 16:34:24,294 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp06k06eu5
INFO 2024-04-09 16:34:27,156 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-09 16:34:28,971 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(196864, rest(789504)
INFO 2024-04-09 16:34:28,971 Check the whole parameters: 141525504 = 141525504
INFO 2024-04-09 16:36:42,509 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-09 16:36:44,040 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-09 16:36:44,076 The size of dataset: train(34231), test(4926)
INFO 2024-04-09 16:36:44,077 Start training
INFO 2024-04-09 16:41:06,928 sss
INFO 2024-04-09 16:41:08,085 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-09 16:41:08,086 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpjuubsbv1
INFO 2024-04-09 16:41:10,969 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-09 16:41:12,910 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(196864, rest(789504)
INFO 2024-04-09 16:41:12,910 Check the whole parameters: 141525504 = 141525504
INFO 2024-04-09 16:43:26,657 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-09 16:43:28,560 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-09 16:43:28,598 The size of dataset: train(34231), test(4926)
INFO 2024-04-09 16:43:28,598 Start training
INFO 2024-04-09 16:59:58,832 iter:0, loss:3.526672840118408, total_2:4762, cnt_2:622, acc:138
INFO 2024-04-09 17:21:47,153 iter:1000, loss:2.141174554824829, total_2:4762, cnt_2:622, acc:395
INFO 2024-04-09 17:43:22,458 iter:2000, loss:2.0282604694366455, total_2:4762, cnt_2:622, acc:423
INFO 2024-04-09 18:04:34,318 iter:3000, loss:1.8417526483535767, total_2:4762, cnt_2:622, acc:472
INFO 2024-04-09 18:23:02,896 sss
INFO 2024-04-09 18:23:04,274 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-09 18:23:04,276 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpaq_qn2x1
INFO 2024-04-09 18:23:07,229 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-09 18:23:09,452 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-09 18:23:09,452 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-09 18:25:22,958 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-09 18:25:24,524 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-09 18:25:24,563 The size of dataset: train(34231), test(4926)
INFO 2024-04-09 18:25:24,564 Start training
INFO 2024-04-09 18:30:36,441 sss
INFO 2024-04-09 18:30:37,767 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-09 18:30:37,768 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpzeiw_wza
INFO 2024-04-09 18:30:40,536 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-09 18:30:42,389 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-09 18:30:42,389 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-09 18:32:56,010 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-09 18:32:57,570 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-09 18:32:57,615 The size of dataset: train(34231), test(4926)
INFO 2024-04-09 18:32:57,615 Start training
INFO 2024-04-09 18:40:51,710 sss
INFO 2024-04-09 18:40:52,863 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-09 18:40:52,865 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpes3td2a4
INFO 2024-04-09 18:40:55,732 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-09 18:40:57,810 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-09 18:40:57,811 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-09 18:43:11,466 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-09 18:43:13,188 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-09 18:43:13,231 The size of dataset: train(34231), test(4926)
INFO 2024-04-09 18:43:13,231 Start training
INFO 2024-04-09 18:50:49,178 sss
INFO 2024-04-09 18:50:50,650 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-09 18:50:50,650 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp_tlkguoo
INFO 2024-04-09 18:50:53,418 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-09 18:50:55,829 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-09 18:50:55,829 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-09 18:53:09,825 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-09 18:53:11,444 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-09 18:53:11,484 The size of dataset: train(34231), test(4926)
INFO 2024-04-09 18:53:11,484 Start training
INFO 2024-04-09 19:05:39,713 sss
INFO 2024-04-09 19:05:40,973 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-09 19:05:40,975 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpbziovm_9
INFO 2024-04-09 19:05:43,801 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-09 19:05:45,955 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-09 19:05:45,955 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-09 19:08:00,484 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-09 19:08:03,513 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-09 19:08:03,554 The size of dataset: train(34231), test(4926)
INFO 2024-04-09 19:08:03,554 Start training
INFO 2024-04-09 19:50:53,236 sss
INFO 2024-04-09 19:50:55,872 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-09 19:50:55,873 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpr7x3b299
INFO 2024-04-09 19:51:01,601 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-09 19:51:03,684 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-09 19:51:03,684 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-09 19:53:18,155 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-09 19:53:19,873 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-09 19:53:19,912 The size of dataset: train(34231), test(4926)
INFO 2024-04-09 19:53:19,913 Start training
INFO 2024-04-09 20:10:28,583 iter:0, loss:3.5145013332366943, total_2:202, cnt_2:15, acc:167
INFO 2024-04-09 20:16:36,385 sss
INFO 2024-04-09 20:16:37,614 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-09 20:16:37,615 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpxbswo_l9
INFO 2024-04-09 20:16:40,643 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-09 20:16:42,702 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-09 20:16:42,702 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-09 20:18:56,401 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-09 20:18:57,930 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-09 20:18:57,970 The size of dataset: train(34231), test(4926)
INFO 2024-04-09 20:18:57,971 Start training
INFO 2024-04-09 20:36:27,462 iter:0, loss:3.5705368518829346, total_2:4762, cnt_2:509, acc:149
INFO 2024-04-09 20:53:29,975 sss
INFO 2024-04-09 20:53:31,141 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-09 20:53:31,142 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpi4s98i31
INFO 2024-04-09 20:53:33,952 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-09 20:53:35,859 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-09 20:53:35,859 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-09 20:55:50,612 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-09 20:55:52,427 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-09 20:55:52,468 The size of dataset: train(34231), test(4926)
INFO 2024-04-09 20:55:52,469 Start training
INFO 2024-04-09 21:13:27,489 iter:0, loss:3.5580203533172607, total_2:0, cnt_2:0, acc:171
INFO 2024-04-09 21:29:22,903 sss
INFO 2024-04-09 21:29:24,006 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-09 21:29:24,007 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpwtr8z60v
INFO 2024-04-09 21:29:26,765 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-09 21:29:28,617 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-09 21:29:28,617 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-09 21:32:17,538 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-09 21:32:19,093 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-09 21:32:19,126 The size of dataset: train(34231), test(4926)
INFO 2024-04-09 21:32:19,126 Start training
INFO 2024-04-09 21:49:19,151 iter:0, loss:3.5048201084136963, total_2:0, cnt_2:0, acc:170
INFO 2024-04-09 21:57:41,649 sss
INFO 2024-04-09 21:57:42,901 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-09 21:57:42,903 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpo133owuy
INFO 2024-04-09 21:57:46,185 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-09 21:57:48,276 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-09 21:57:48,276 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-09 22:00:02,306 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-09 22:00:04,032 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-09 22:00:04,090 The size of dataset: train(34231), test(4926)
INFO 2024-04-09 22:00:04,091 Start training
INFO 2024-04-09 22:17:02,084 iter:0, loss:3.548161506652832, total_2:3866, cnt_2:392, acc:151
INFO 2024-04-09 22:39:11,474 iter:1000, loss:2.124297618865967, total_2:0, cnt_2:0, acc:382
INFO 2024-04-09 22:48:24,466 sss
INFO 2024-04-09 22:48:25,856 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-09 22:48:25,857 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpmn96vwdn
INFO 2024-04-09 22:48:28,731 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-09 22:48:30,628 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-09 22:48:30,629 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-09 22:50:44,244 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-09 22:50:45,939 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-09 22:50:45,980 The size of dataset: train(34231), test(4926)
INFO 2024-04-09 22:50:45,981 Start training
INFO 2024-04-09 23:07:43,591 iter:0, loss:3.5358481407165527, total_2:4762, cnt_2:508, acc:151
INFO 2024-04-09 23:28:52,853 sss
INFO 2024-04-09 23:28:53,949 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-09 23:28:53,950 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp0p0i57ke
INFO 2024-04-09 23:28:56,639 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-09 23:28:58,561 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-09 23:28:58,561 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-09 23:31:12,585 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-09 23:31:14,509 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-09 23:31:14,549 The size of dataset: train(34231), test(4926)
INFO 2024-04-09 23:31:14,550 Start training
INFO 2024-04-10 00:07:47,713 sss
INFO 2024-04-10 00:07:49,003 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-10 00:07:49,064 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpb7oqim3w
INFO 2024-04-10 00:07:51,774 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-10 00:07:53,578 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-10 00:07:53,578 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-10 00:10:07,088 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 00:10:08,770 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 00:10:08,806 The size of dataset: train(34231), test(4926)
INFO 2024-04-10 00:10:08,806 Start training
INFO 2024-04-10 00:34:55,103 sss
INFO 2024-04-10 00:34:56,206 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-10 00:34:56,207 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp1jinjk3r
INFO 2024-04-10 00:34:58,963 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-10 00:35:00,937 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-10 00:35:00,937 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-10 00:37:14,504 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 00:37:16,161 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 00:37:16,198 The size of dataset: train(34231), test(4926)
INFO 2024-04-10 00:37:16,198 Start training
INFO 2024-04-10 00:57:19,087 sss
INFO 2024-04-10 00:57:20,239 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-10 00:57:20,240 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp6a7jf8_8
INFO 2024-04-10 00:57:23,181 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-10 00:57:25,025 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-10 00:57:25,025 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-10 00:59:38,780 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 00:59:40,361 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 00:59:40,400 The size of dataset: train(34231), test(4926)
INFO 2024-04-10 00:59:40,400 Start training
INFO 2024-04-10 01:13:09,195 sss
INFO 2024-04-10 01:13:10,577 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-10 01:13:10,578 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpegoipx9p
INFO 2024-04-10 01:13:13,456 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-10 01:13:15,426 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-10 01:13:15,426 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-10 01:15:29,753 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 01:15:31,570 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 01:15:31,617 The size of dataset: train(34231), test(4926)
INFO 2024-04-10 01:15:31,618 Start training
INFO 2024-04-10 01:33:07,877 iter:0, loss:3.489060401916504, total_2:4762, cnt_2:547, acc:135
INFO 2024-04-10 01:38:57,759 sss
INFO 2024-04-10 01:38:59,056 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-10 01:38:59,057 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp85utw5to
INFO 2024-04-10 01:39:01,800 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-10 01:39:03,697 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-10 01:39:03,697 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-10 01:41:17,381 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 01:41:19,131 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 01:41:19,170 The size of dataset: train(34231), test(4926)
INFO 2024-04-10 01:41:19,170 Start training
INFO 2024-04-10 02:09:55,965 sss
INFO 2024-04-10 02:09:57,183 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-10 02:09:57,184 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpcu7xu706
INFO 2024-04-10 02:09:59,922 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-10 02:10:01,867 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-10 02:10:01,867 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-10 02:12:15,422 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 02:12:17,134 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 02:12:17,175 The size of dataset: train(34231), test(4926)
INFO 2024-04-10 02:12:17,176 Start training
INFO 2024-04-10 02:21:37,679 sss
INFO 2024-04-10 02:21:38,904 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-10 02:21:38,904 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp4kw4gt0p
INFO 2024-04-10 02:21:41,721 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-10 02:21:43,629 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-10 02:21:43,630 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-10 02:23:57,041 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 02:23:58,908 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 02:23:58,945 The size of dataset: train(34231), test(4926)
INFO 2024-04-10 02:23:58,946 Start training
INFO 2024-04-10 02:32:41,070 sss
INFO 2024-04-10 02:32:42,163 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-10 02:32:42,164 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpgw4ywyb2
INFO 2024-04-10 02:32:44,912 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-10 02:32:46,861 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-10 02:32:46,861 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-10 02:35:00,470 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 02:35:02,072 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 02:35:02,111 The size of dataset: train(34231), test(4926)
INFO 2024-04-10 02:35:02,111 Start training
INFO 2024-04-10 02:51:58,191 iter:0, loss:3.557203531265259, total_2:1, cnt_2:0, acc:168
INFO 2024-04-10 03:18:42,479 sss
INFO 2024-04-10 03:18:43,620 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-10 03:18:43,621 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp8qemfnca
INFO 2024-04-10 03:18:46,393 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-10 03:18:48,179 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-10 03:18:48,180 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-10 03:21:01,722 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 03:21:03,246 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 03:21:03,282 The size of dataset: train(34231), test(4926)
INFO 2024-04-10 03:21:03,283 Start training
INFO 2024-04-10 03:30:02,624 sss
INFO 2024-04-10 03:30:03,782 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-10 03:30:03,783 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpw0l8uwej
INFO 2024-04-10 03:30:06,519 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-10 03:30:08,417 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-10 03:30:08,418 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-10 03:32:21,872 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 03:32:23,733 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 03:32:23,770 The size of dataset: train(34231), test(4926)
INFO 2024-04-10 03:32:23,770 Start training
INFO 2024-04-10 03:42:38,365 sss
INFO 2024-04-10 03:42:39,452 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-10 03:42:39,454 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpo1vjdh4l
INFO 2024-04-10 03:42:42,174 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-10 03:42:44,046 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-10 03:42:44,046 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-10 03:44:57,540 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 03:44:59,307 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 03:44:59,345 The size of dataset: train(34231), test(4926)
INFO 2024-04-10 03:44:59,345 Start training
INFO 2024-04-10 03:52:04,427 sss
INFO 2024-04-10 03:52:05,512 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-10 03:52:05,512 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpxo9ddrvg
INFO 2024-04-10 03:52:08,249 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-10 03:52:09,999 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-10 03:52:09,999 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-10 03:54:23,692 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 03:54:25,359 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 03:54:25,399 The size of dataset: train(34231), test(4926)
INFO 2024-04-10 03:54:25,399 Start training
INFO 2024-04-10 04:07:15,824 sss
INFO 2024-04-10 04:07:17,291 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-10 04:07:17,292 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp351ytsnu
INFO 2024-04-10 04:07:20,070 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-10 04:07:21,932 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-10 04:07:21,932 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-10 04:09:35,391 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 04:09:36,901 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 04:09:36,938 The size of dataset: train(34231), test(4926)
INFO 2024-04-10 04:09:36,939 Start training
INFO 2024-04-10 04:14:08,606 sss
INFO 2024-04-10 04:14:09,991 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-10 04:14:09,992 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp_kt1ohrn
INFO 2024-04-10 04:14:12,683 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-10 04:14:14,557 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-10 04:14:14,558 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-10 04:16:28,080 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 04:16:29,815 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 04:16:29,853 The size of dataset: train(34231), test(4926)
INFO 2024-04-10 04:16:29,854 Start training
INFO 2024-04-10 04:19:57,520 sss
INFO 2024-04-10 04:19:58,759 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-10 04:19:58,760 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp3x0bqv5n
INFO 2024-04-10 04:20:01,494 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-10 04:20:03,371 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-10 04:20:03,371 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-10 04:21:06,890 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 04:21:08,391 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 04:21:08,438 The size of dataset: train(34231), test(4926)
INFO 2024-04-10 04:21:08,438 Start training
INFO 2024-04-10 04:28:21,465 sss
INFO 2024-04-10 04:28:22,520 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-10 04:28:22,522 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpd_ounfmk
INFO 2024-04-10 04:28:25,278 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-10 04:28:27,294 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-10 04:28:27,294 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-10 04:30:40,845 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 04:30:42,525 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 04:30:42,562 The size of dataset: train(34231), test(4926)
INFO 2024-04-10 04:30:42,562 Start training
INFO 2024-04-10 04:34:18,081 sss
INFO 2024-04-10 04:34:19,418 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-10 04:34:19,419 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp3yk7b54o
INFO 2024-04-10 04:34:22,116 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-10 04:34:23,900 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-10 04:34:23,900 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-10 04:36:37,301 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 04:36:38,928 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 04:36:38,965 The size of dataset: train(34231), test(4926)
INFO 2024-04-10 04:36:38,965 Start training
INFO 2024-04-10 04:45:04,378 sss
INFO 2024-04-10 04:45:05,474 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-10 04:45:05,475 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp0cmmhczb
INFO 2024-04-10 04:45:08,179 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-10 04:45:10,083 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-10 04:45:10,083 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-10 04:47:23,589 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 04:47:25,237 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 04:47:25,275 The size of dataset: train(34231), test(4926)
INFO 2024-04-10 04:47:25,275 Start training
INFO 2024-04-10 04:54:04,611 sss
INFO 2024-04-10 04:54:05,723 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-10 04:54:05,724 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpzg4qm8nm
INFO 2024-04-10 04:54:08,477 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-10 04:54:10,411 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-10 04:54:10,411 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-10 04:56:23,999 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 04:56:26,134 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 04:56:26,183 The size of dataset: train(34231), test(4926)
INFO 2024-04-10 04:56:26,184 Start training
INFO 2024-04-10 05:01:02,764 sss
INFO 2024-04-10 05:01:04,125 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-10 05:01:04,126 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpzfe0h6of
INFO 2024-04-10 05:01:06,886 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-10 05:01:08,832 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-10 05:01:08,833 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-10 05:01:12,893 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 05:01:14,766 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 05:01:14,808 The size of dataset: train(34231), test(4926)
INFO 2024-04-10 05:01:14,809 Start training
INFO 2024-04-10 05:07:49,272 sss
INFO 2024-04-10 05:07:50,410 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-10 05:07:50,411 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpn83aallb
INFO 2024-04-10 05:07:53,139 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-10 05:07:54,970 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-10 05:07:54,970 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-10 05:10:08,776 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 05:10:10,472 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 05:10:10,510 The size of dataset: train(34231), test(4926)
INFO 2024-04-10 05:10:10,511 Start training
INFO 2024-04-10 05:26:59,886 iter:0, loss:3.567800521850586, total_2:0, cnt_2:0, acc:165
INFO 2024-04-10 05:34:31,218 sss
INFO 2024-04-10 05:34:32,417 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-10 05:34:32,418 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmptl23kdnr
INFO 2024-04-10 05:34:35,213 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-10 05:34:43,712 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-10 05:34:43,712 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-10 05:36:57,440 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 05:36:59,010 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 05:36:59,046 The size of dataset: train(34231), test(4926)
INFO 2024-04-10 05:36:59,046 Start training
INFO 2024-04-10 05:53:48,001 iter:0, loss:3.496551036834717, total_2:2972, cnt_2:412, acc:152
INFO 2024-04-10 06:22:53,181 iter:1000, loss:2.112647294998169, total_2:0, cnt_2:0, acc:381
INFO 2024-04-10 06:52:42,680 iter:2000, loss:1.932002305984497, total_2:0, cnt_2:0, acc:446
INFO 2024-04-10 07:22:13,447 iter:3000, loss:1.8961589336395264, total_2:4762, cnt_2:601, acc:472
INFO 2024-04-10 07:51:33,901 iter:4000, loss:1.8351362943649292, total_2:4762, cnt_2:599, acc:470
INFO 2024-04-10 08:20:51,347 iter:5000, loss:1.779850959777832, total_2:4762, cnt_2:597, acc:488
INFO 2024-04-10 08:49:23,474 iter:6000, loss:1.821509599685669, total_2:4762, cnt_2:598, acc:501
INFO 2024-04-10 09:18:35,513 iter:7000, loss:1.7741525173187256, total_2:0, cnt_2:0, acc:512
INFO 2024-04-10 09:47:51,459 iter:8000, loss:1.7160717248916626, total_2:4762, cnt_2:598, acc:509
INFO 2024-04-10 09:57:04,797 train_epoch:0, total_1:0, cnt_1:0, total_2:20939, cnt_2:2989
INFO 2024-04-10 16:03:49,729 sss
INFO 2024-04-10 16:03:52,511 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-10 16:03:52,512 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp43bkbvvu
INFO 2024-04-10 16:03:57,634 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-10 16:04:12,279 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-10 16:04:12,279 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-10 16:06:27,178 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 16:06:29,811 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 16:06:29,871 The size of dataset: train(34231), test(4926)
INFO 2024-04-10 16:06:29,871 Start training
INFO 2024-04-10 16:46:38,706 sss
INFO 2024-04-10 16:46:40,061 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-10 16:46:40,062 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpmaf0ez7x
INFO 2024-04-10 16:46:42,787 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-10 16:46:50,185 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-10 16:46:50,185 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-10 16:49:03,456 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 16:49:04,952 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 16:49:04,996 The size of dataset: train(34231), test(4926)
INFO 2024-04-10 16:49:04,997 Start training
INFO 2024-04-10 21:34:04,302 train_epoch:0, total_1:0, cnt_1:0, total_2:6411, cnt_2:723
INFO 2024-04-10 21:45:15,289 epoch:0, loss:1.7067664861679077, total_2:0, cnt_2:0, acc:512
INFO 2024-04-10 22:20:43,331 sss
INFO 2024-04-10 22:20:44,609 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-10 22:20:44,610 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpav9bpste
INFO 2024-04-10 22:20:47,138 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-10 22:20:49,092 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-10 22:20:49,092 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-10 22:23:02,119 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 22:23:03,490 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 22:23:03,525 The size of dataset: train(34231), test(4926)
INFO 2024-04-10 22:23:03,525 Start training
INFO 2024-04-10 22:55:30,386 sss
INFO 2024-04-10 22:55:31,779 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-10 22:55:31,780 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp3nlia0v0
INFO 2024-04-10 22:55:34,280 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-10 22:55:41,233 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-10 22:55:41,233 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-10 22:57:55,615 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 22:57:56,885 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 22:57:56,920 The size of dataset: train(19117), test(4927)
INFO 2024-04-10 22:57:56,920 Start training
INFO 2024-04-10 23:01:33,738 sss
INFO 2024-04-10 23:01:34,791 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-10 23:01:34,792 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpsv4s8s0n
INFO 2024-04-10 23:01:37,299 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-10 23:01:44,176 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-10 23:01:44,176 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-10 23:03:56,991 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 23:03:58,249 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 23:03:58,284 The size of dataset: train(19117), test(4927)
INFO 2024-04-10 23:03:58,285 Start training
INFO 2024-04-10 23:12:06,896 sss
INFO 2024-04-10 23:12:07,956 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-10 23:12:07,957 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp_on4x8ki
INFO 2024-04-10 23:12:10,470 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-10 23:12:17,439 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-10 23:12:17,439 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-10 23:14:30,489 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 23:14:31,815 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 23:14:31,849 The size of dataset: train(34231), test(4926)
INFO 2024-04-10 23:14:31,849 Start training
INFO 2024-04-10 23:29:55,187 iter:0, loss:3.5296201705932617, total_2:2822, cnt_2:408, acc:144
INFO 2024-04-10 23:51:16,845 iter:1000, loss:2.175446033477783, total_2:2822, cnt_2:408, acc:346
INFO 2024-04-10 23:56:04,405 sss
INFO 2024-04-10 23:56:05,480 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-10 23:56:05,484 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpky50wuop
INFO 2024-04-10 23:56:08,154 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-10 23:56:16,078 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-10 23:56:16,078 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-10 23:58:28,993 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 23:58:30,283 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-10 23:58:30,313 The size of dataset: train(34231), test(4926)
INFO 2024-04-10 23:58:30,313 Start training
INFO 2024-04-11 00:02:28,918 sss
INFO 2024-04-11 00:02:29,950 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-11 00:02:29,951 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpxjzkrfue
INFO 2024-04-11 00:02:32,496 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-11 00:02:39,517 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-11 00:02:39,517 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-11 00:04:52,728 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-11 00:04:54,339 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-11 00:04:54,371 The size of dataset: train(34231), test(4926)
INFO 2024-04-11 00:04:54,371 Start training
INFO 2024-04-11 00:20:54,587 iter:0, loss:3.562805652618408, total_2:2822, cnt_2:410, acc:149
INFO 2024-04-11 00:43:55,469 iter:1000, loss:2.1897213459014893, total_2:2822, cnt_2:410, acc:341
INFO 2024-04-11 01:07:07,601 iter:2000, loss:1.9764503240585327, total_2:2822, cnt_2:410, acc:441
INFO 2024-04-11 01:30:31,365 iter:3000, loss:1.8611459732055664, total_2:2822, cnt_2:410, acc:457
INFO 2024-04-11 01:53:43,883 iter:4000, loss:1.8443831205368042, total_2:2822, cnt_2:410, acc:469
INFO 2024-04-11 02:16:49,855 iter:5000, loss:1.8130825757980347, total_2:2822, cnt_2:410, acc:486
INFO 2024-04-11 02:39:32,669 iter:6000, loss:1.8443166017532349, total_2:2822, cnt_2:410, acc:473
INFO 2024-04-11 03:02:49,146 iter:7000, loss:1.7993505001068115, total_2:2822, cnt_2:410, acc:490
INFO 2024-04-11 03:25:54,823 iter:8000, loss:1.8191062211990356, total_2:2822, cnt_2:410, acc:509
INFO 2024-04-11 03:31:32,527 train_epoch:0, total_1:0, cnt_1:0, total_2:19727, cnt_2:3187
INFO 2024-04-11 03:44:17,789 epoch:0, loss:1.7806023359298706, total_2:2822, cnt_2:410, acc:512
INFO 2024-04-11 03:57:32,235 iter:0, loss:1.7553130388259888, total_2:2822, cnt_2:410, acc:512
INFO 2024-04-11 04:21:06,314 iter:1000, loss:1.7550928592681885, total_2:2822, cnt_2:410, acc:517
INFO 2024-04-11 04:44:06,901 iter:2000, loss:1.7365869283676147, total_2:2822, cnt_2:410, acc:518
INFO 2024-04-11 05:07:01,274 iter:3000, loss:1.718641996383667, total_2:2822, cnt_2:410, acc:521
INFO 2024-04-11 05:30:14,647 iter:4000, loss:1.7773957252502441, total_2:2822, cnt_2:410, acc:514
INFO 2024-04-11 05:53:21,282 iter:5000, loss:1.7275208234786987, total_2:2822, cnt_2:410, acc:510
INFO 2024-04-11 06:16:26,201 iter:6000, loss:1.6740154027938843, total_2:2822, cnt_2:410, acc:516
INFO 2024-04-11 06:39:38,651 iter:7000, loss:1.761404037475586, total_2:2822, cnt_2:410, acc:507
INFO 2024-04-11 07:02:22,663 iter:8000, loss:1.7996464967727661, total_2:2822, cnt_2:410, acc:501
INFO 2024-04-11 07:07:57,812 train_epoch:1, total_1:0, cnt_1:0, total_2:19732, cnt_2:3179
INFO 2024-04-11 07:20:29,758 epoch:1, loss:1.737680196762085, total_2:2822, cnt_2:410, acc:510
INFO 2024-04-11 07:33:47,480 iter:0, loss:1.7875138521194458, total_2:2822, cnt_2:410, acc:510
INFO 2024-04-11 07:56:50,166 iter:1000, loss:1.7198965549468994, total_2:2822, cnt_2:410, acc:527
INFO 2024-04-11 08:19:56,101 iter:2000, loss:1.7689528465270996, total_2:2822, cnt_2:410, acc:514
INFO 2024-04-11 08:43:09,822 iter:3000, loss:1.7475316524505615, total_2:2822, cnt_2:410, acc:522
INFO 2024-04-11 09:06:09,563 iter:4000, loss:1.7124344110488892, total_2:2822, cnt_2:410, acc:512
INFO 2024-04-11 09:29:06,420 iter:5000, loss:1.724942684173584, total_2:2822, cnt_2:410, acc:515
INFO 2024-04-11 09:52:02,033 iter:6000, loss:1.6671475172042847, total_2:2822, cnt_2:410, acc:525
INFO 2024-04-11 10:14:59,862 iter:7000, loss:1.741782784461975, total_2:2822, cnt_2:410, acc:519
INFO 2024-04-11 10:38:01,935 iter:8000, loss:1.7810636758804321, total_2:2822, cnt_2:410, acc:514
INFO 2024-04-11 10:43:36,296 train_epoch:2, total_1:0, cnt_1:0, total_2:19736, cnt_2:3180
INFO 2024-04-11 10:56:15,192 epoch:2, loss:1.7659331560134888, total_2:2822, cnt_2:410, acc:515
INFO 2024-04-11 11:09:40,047 iter:0, loss:1.7657848596572876, total_2:2822, cnt_2:410, acc:515
INFO 2024-04-11 11:32:34,852 iter:1000, loss:1.7080706357955933, total_2:2822, cnt_2:410, acc:525
INFO 2024-04-11 11:52:03,181 sss
INFO 2024-04-11 11:52:04,592 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-11 11:52:04,593 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpp8d_cotp
INFO 2024-04-11 11:52:07,253 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-11 11:52:15,830 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-11 11:52:15,830 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-11 11:54:29,352 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-11 11:54:30,661 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-11 11:54:30,694 The size of dataset: train(34231), test(4926)
INFO 2024-04-11 11:54:30,694 Start training
INFO 2024-04-11 12:01:23,490 sss
INFO 2024-04-11 12:01:24,701 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-11 12:01:24,703 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpe6alku78
INFO 2024-04-11 12:01:27,429 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-11 12:01:35,587 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-11 12:01:35,587 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-11 12:01:38,668 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-11 12:01:40,092 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-11 12:01:40,135 The size of dataset: train(34231), test(4926)
INFO 2024-04-11 12:01:40,136 Start training
INFO 2024-04-11 12:23:18,888 sss
INFO 2024-04-11 12:23:19,982 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-11 12:23:19,983 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpcnkzj5x8
INFO 2024-04-11 12:23:22,634 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-11 12:23:30,710 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-11 12:23:30,710 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-11 12:25:43,697 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-11 12:25:45,104 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-11 12:25:45,143 The size of dataset: train(34231), test(4926)
INFO 2024-04-11 12:25:45,144 Start training
INFO 2024-04-11 12:43:10,351 iter:0, loss:3.4912354946136475, total_2:2822, cnt_2:411, acc:177
INFO 2024-04-11 13:37:39,574 sss
INFO 2024-04-11 13:37:40,623 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-11 13:37:40,624 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp65whtn8z
INFO 2024-04-11 13:37:43,239 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-11 13:37:49,927 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-11 13:37:49,928 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-11 13:40:03,170 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-11 13:40:04,717 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-11 13:40:04,763 The size of dataset: train(34231), test(4926)
INFO 2024-04-11 13:40:04,764 Start training
INFO 2024-04-11 14:06:12,185 sss
INFO 2024-04-11 14:06:13,301 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-11 14:06:13,303 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp508nnuaj
INFO 2024-04-11 14:06:15,885 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-11 14:06:21,996 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-11 14:06:21,996 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-11 14:08:35,188 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-11 14:08:36,523 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-11 14:08:36,559 The size of dataset: train(34231), test(4926)
INFO 2024-04-11 14:08:36,559 Start training
INFO 2024-04-11 14:41:01,598 sss
INFO 2024-04-11 14:41:02,699 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-11 14:41:02,701 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpkn10tq53
INFO 2024-04-11 14:41:05,300 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-11 14:41:11,615 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-11 14:41:11,615 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-11 14:43:25,333 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-11 14:43:27,111 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-11 14:43:27,155 The size of dataset: train(34231), test(4926)
INFO 2024-04-11 14:43:27,156 Start training
INFO 2024-04-11 14:55:22,275 sss
INFO 2024-04-11 14:55:23,287 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-11 14:55:23,288 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpptq2zkr5
INFO 2024-04-11 14:55:25,949 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-11 14:55:49,236 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-11 14:55:49,236 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-11 14:58:02,342 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-11 14:58:03,653 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-11 14:58:03,690 The size of dataset: train(34231), test(4926)
INFO 2024-04-11 14:58:03,691 Start training
INFO 2024-04-11 15:16:25,860 sss
INFO 2024-04-11 15:16:27,079 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-11 15:16:27,079 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp4lm4y6h2
INFO 2024-04-11 15:16:29,701 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-11 15:16:52,312 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-11 15:16:52,312 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-11 15:19:05,951 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-11 15:19:07,571 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-11 15:19:07,606 The size of dataset: train(34231), test(4926)
INFO 2024-04-11 15:19:07,606 Start training
INFO 2024-04-11 15:39:08,900 sss
INFO 2024-04-11 15:39:10,145 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-11 15:39:10,146 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpw22d61q7
INFO 2024-04-11 15:39:12,827 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-11 15:39:35,549 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-11 15:39:35,549 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-11 15:41:48,901 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-11 15:41:50,543 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-11 15:41:50,576 The size of dataset: train(34231), test(4926)
INFO 2024-04-11 15:41:50,577 Start training
INFO 2024-04-11 16:10:08,738 sss
INFO 2024-04-11 16:10:09,948 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-11 16:10:10,008 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpu9j4ylms
INFO 2024-04-11 16:10:12,968 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-11 16:10:44,903 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-11 16:10:44,903 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-11 16:12:59,364 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-11 16:13:00,830 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-11 16:13:00,862 The size of dataset: train(34231), test(4926)
INFO 2024-04-11 16:13:00,862 Start training
INFO 2024-04-11 16:28:46,914 sss
INFO 2024-04-11 16:28:48,082 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-11 16:28:48,083 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp7gxvgk0i
INFO 2024-04-11 16:28:50,824 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-11 16:29:21,055 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-11 16:29:21,055 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-11 16:31:34,719 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-11 16:31:36,319 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-11 16:31:36,353 The size of dataset: train(34231), test(4926)
INFO 2024-04-11 16:31:36,353 Start training
INFO 2024-04-11 16:41:36,391 sss
INFO 2024-04-11 16:41:37,718 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-11 16:41:37,719 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp98tugi9m
INFO 2024-04-11 16:41:40,483 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-11 16:41:59,488 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-11 16:41:59,489 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-11 16:44:13,120 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-11 16:44:14,886 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-11 16:44:14,924 The size of dataset: train(34231), test(4926)
INFO 2024-04-11 16:44:14,925 Start training
INFO 2024-04-11 18:00:57,509 sss
INFO 2024-04-11 18:00:58,664 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-11 18:00:58,668 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp7xa8rhtq
INFO 2024-04-11 18:01:01,315 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-11 18:01:06,224 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-11 18:01:06,224 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-11 18:03:19,451 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-11 18:03:20,800 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-11 18:03:20,830 The size of dataset: train(34231), test(4926)
INFO 2024-04-11 18:03:20,830 Start training
INFO 2024-04-11 21:09:32,022 sss
INFO 2024-04-11 21:09:33,498 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-11 21:09:33,499 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpgazknm3p
INFO 2024-04-11 21:09:36,180 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-11 21:09:41,004 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-11 21:09:41,004 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-11 21:11:54,503 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-11 21:11:56,263 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-11 21:11:56,295 The size of dataset: train(34231), test(4926)
INFO 2024-04-11 21:11:56,295 Start training
INFO 2024-04-11 21:22:07,499 sss
INFO 2024-04-11 21:22:08,885 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-11 21:22:08,886 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpnt_f8d0g
INFO 2024-04-11 21:22:11,507 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-11 21:22:30,195 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-11 21:22:30,195 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-11 21:24:43,654 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-11 21:24:45,146 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-11 21:24:45,178 The size of dataset: train(34231), test(4926)
INFO 2024-04-11 21:24:45,178 Start training
INFO 2024-04-11 21:29:20,181 sss
INFO 2024-04-11 21:29:21,652 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-11 21:29:21,653 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpgn8t2y5e
INFO 2024-04-11 21:29:24,287 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-11 21:29:45,852 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-11 21:29:45,852 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-11 21:31:59,044 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-11 21:32:00,510 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-11 21:32:00,538 The size of dataset: train(34231), test(4926)
INFO 2024-04-11 21:32:00,538 Start training
INFO 2024-04-11 21:36:54,875 sss
INFO 2024-04-11 21:36:55,919 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-11 21:36:55,920 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp4picm34e
INFO 2024-04-11 21:36:58,665 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-11 21:37:20,760 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-11 21:37:20,760 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-11 21:41:44,744 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-11 21:41:46,432 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-11 21:41:46,468 The size of dataset: train(34231), test(4926)
INFO 2024-04-11 21:41:46,468 Start training
INFO 2024-04-11 22:05:31,357 sss
INFO 2024-04-11 22:05:32,676 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-11 22:05:32,676 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpzntfu66z
INFO 2024-04-11 22:05:35,448 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-11 22:05:56,948 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-11 22:05:56,948 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-11 22:08:11,051 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-11 22:08:12,816 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-11 22:08:12,850 The size of dataset: train(34231), test(4926)
INFO 2024-04-11 22:08:12,850 Start training
INFO 2024-04-11 23:54:37,754 iter:0, loss:3.588015556335449, total_2:2822, cnt_2:453, acc:634
INFO 2024-04-12 00:00:00,853 sss
INFO 2024-04-12 00:00:02,353 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-12 00:00:02,354 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmps9cdcu55
INFO 2024-04-12 00:00:05,022 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-12 00:00:07,171 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-12 00:00:07,171 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-12 00:02:20,435 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-12 00:02:22,180 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-12 00:02:22,216 The size of dataset: train(34231), test(4926)
INFO 2024-04-12 00:02:22,216 Start training
INFO 2024-04-12 00:22:06,516 iter:1000, loss:2.167881727218628, total_2:2822, cnt_2:411, acc:1417
INFO 2024-04-12 00:40:36,610 iter:2000, loss:2.0580525398254395, total_2:2822, cnt_2:411, acc:1710
INFO 2024-04-12 00:58:55,235 iter:3000, loss:1.943023443222046, total_2:2822, cnt_2:411, acc:1850
INFO 2024-04-12 01:17:15,193 iter:4000, loss:1.9199795722961426, total_2:2822, cnt_2:411, acc:1898
INFO 2024-04-12 01:35:32,230 iter:5000, loss:1.8497276306152344, total_2:2822, cnt_2:411, acc:1939
INFO 2024-04-12 01:53:21,598 iter:6000, loss:1.8213796615600586, total_2:2822, cnt_2:411, acc:1950
INFO 2024-04-12 02:11:42,072 iter:7000, loss:1.8062752485275269, total_2:2822, cnt_2:411, acc:1922
INFO 2024-04-12 02:29:44,863 iter:8000, loss:1.7967355251312256, total_2:2822, cnt_2:411, acc:1996
INFO 2024-04-12 02:34:58,637 train_epoch:0, total_1:0, cnt_1:0, total_2:19725, cnt_2:3273
INFO 2024-04-12 02:43:36,429 epoch:0, loss:1.8570023775100708, total_2:2822, cnt_2:411, acc:2010
INFO 2024-04-12 03:03:02,192 iter:1000, loss:1.7715810537338257, total_2:2822, cnt_2:411, acc:2026
INFO 2024-04-12 03:21:15,788 iter:2000, loss:1.761091709136963, total_2:2822, cnt_2:411, acc:2003
INFO 2024-04-12 03:39:30,791 iter:3000, loss:1.8178457021713257, total_2:2822, cnt_2:411, acc:2047
INFO 2024-04-12 03:57:58,256 iter:4000, loss:1.8188410997390747, total_2:2822, cnt_2:411, acc:2083
INFO 2024-04-12 04:16:05,863 iter:5000, loss:1.6743675470352173, total_2:2822, cnt_2:411, acc:2093
INFO 2024-04-12 04:33:47,091 iter:6000, loss:1.8306914567947388, total_2:2822, cnt_2:411, acc:2070
INFO 2024-04-12 04:51:46,740 iter:7000, loss:1.7051430940628052, total_2:2822, cnt_2:411, acc:2073
INFO 2024-04-12 05:09:59,492 iter:8000, loss:1.7542272806167603, total_2:2822, cnt_2:411, acc:2085
INFO 2024-04-12 05:15:09,252 train_epoch:1, total_1:0, cnt_1:0, total_2:19711, cnt_2:3254
INFO 2024-04-12 05:23:52,020 epoch:1, loss:1.7311722040176392, total_2:2822, cnt_2:411, acc:2100
INFO 2024-04-12 05:43:06,579 iter:1000, loss:1.7017463445663452, total_2:2822, cnt_2:411, acc:2053
INFO 2024-04-12 06:01:02,251 iter:2000, loss:1.8270463943481445, total_2:2822, cnt_2:411, acc:2075
INFO 2024-04-12 06:19:05,274 iter:3000, loss:1.6714370250701904, total_2:2822, cnt_2:411, acc:2058
INFO 2024-04-12 06:37:05,505 iter:4000, loss:1.761122465133667, total_2:2822, cnt_2:411, acc:2094
INFO 2024-04-12 06:55:03,669 iter:5000, loss:1.795586347579956, total_2:2822, cnt_2:411, acc:2123
INFO 2024-04-12 07:13:00,586 iter:6000, loss:1.8036328554153442, total_2:2822, cnt_2:411, acc:2097
INFO 2024-04-12 07:31:00,610 iter:7000, loss:1.854264497756958, total_2:2822, cnt_2:411, acc:2086
INFO 2024-04-12 07:48:49,117 iter:8000, loss:1.8096415996551514, total_2:2822, cnt_2:411, acc:2109
INFO 2024-04-12 07:53:55,865 train_epoch:2, total_1:0, cnt_1:0, total_2:19708, cnt_2:3256
INFO 2024-04-12 08:02:37,139 epoch:2, loss:1.7869118452072144, total_2:2822, cnt_2:411, acc:2096
INFO 2024-04-12 08:21:37,112 iter:1000, loss:1.7831454277038574, total_2:2822, cnt_2:411, acc:2085
INFO 2024-04-12 08:39:34,789 iter:2000, loss:1.8123232126235962, total_2:2822, cnt_2:411, acc:2079
INFO 2024-04-12 08:57:34,877 iter:3000, loss:1.7857890129089355, total_2:2822, cnt_2:411, acc:2108
INFO 2024-04-12 09:15:52,608 iter:4000, loss:1.8496495485305786, total_2:2822, cnt_2:411, acc:2092
INFO 2024-04-12 09:33:49,429 iter:5000, loss:1.7774356603622437, total_2:2822, cnt_2:411, acc:2107
INFO 2024-04-12 09:51:45,615 iter:6000, loss:1.8474079370498657, total_2:2822, cnt_2:411, acc:2099
INFO 2024-04-12 10:08:56,393 iter:7000, loss:1.7894352674484253, total_2:2822, cnt_2:411, acc:2083
INFO 2024-04-12 10:26:09,934 iter:8000, loss:1.6787596940994263, total_2:2822, cnt_2:411, acc:2080
INFO 2024-04-12 10:31:00,781 train_epoch:3, total_1:0, cnt_1:0, total_2:19704, cnt_2:3263
INFO 2024-04-12 10:39:20,561 epoch:3, loss:1.7688231468200684, total_2:2822, cnt_2:411, acc:2111
INFO 2024-04-12 10:57:21,603 iter:1000, loss:1.806861162185669, total_2:2822, cnt_2:411, acc:2067
INFO 2024-04-12 11:14:51,454 iter:2000, loss:1.8051886558532715, total_2:2822, cnt_2:411, acc:2066
INFO 2024-04-12 11:32:16,349 iter:3000, loss:1.7495354413986206, total_2:2822, cnt_2:411, acc:2085
INFO 2024-04-12 11:50:09,264 iter:4000, loss:1.7934142351150513, total_2:2822, cnt_2:411, acc:2099
INFO 2024-04-12 12:07:58,090 iter:5000, loss:1.889289379119873, total_2:2822, cnt_2:411, acc:2068
INFO 2024-04-12 12:25:15,058 iter:6000, loss:1.8363709449768066, total_2:2822, cnt_2:411, acc:2102
INFO 2024-04-12 12:42:41,038 iter:7000, loss:1.8347768783569336, total_2:2822, cnt_2:411, acc:2099
INFO 2024-04-12 13:00:15,156 iter:8000, loss:1.7929621934890747, total_2:2822, cnt_2:411, acc:2022
INFO 2024-04-12 13:05:11,884 train_epoch:4, total_1:0, cnt_1:0, total_2:19716, cnt_2:3245
INFO 2024-04-12 13:13:50,057 epoch:4, loss:1.8164334297180176, total_2:2822, cnt_2:411, acc:2081
INFO 2024-04-12 13:32:26,716 iter:1000, loss:1.8818590641021729, total_2:2822, cnt_2:411, acc:2107
INFO 2024-04-12 13:50:13,396 iter:2000, loss:1.8154222965240479, total_2:2822, cnt_2:411, acc:2055
INFO 2024-04-12 14:07:48,153 iter:3000, loss:1.7631422281265259, total_2:2822, cnt_2:411, acc:2079
INFO 2024-04-12 14:25:35,998 iter:4000, loss:1.7846033573150635, total_2:2822, cnt_2:411, acc:2090
INFO 2024-04-12 14:43:06,934 iter:5000, loss:1.8293300867080688, total_2:2822, cnt_2:411, acc:2107
INFO 2024-04-12 15:00:33,642 iter:6000, loss:1.838972806930542, total_2:2822, cnt_2:411, acc:2034
INFO 2024-04-12 15:18:34,268 iter:7000, loss:1.8149393796920776, total_2:2822, cnt_2:411, acc:2053
INFO 2024-04-12 15:37:24,425 iter:8000, loss:1.8378316164016724, total_2:2822, cnt_2:411, acc:2015
INFO 2024-04-12 15:42:57,847 train_epoch:5, total_1:0, cnt_1:0, total_2:19718, cnt_2:3251
INFO 2024-04-12 15:51:30,733 epoch:5, loss:1.8130332231521606, total_2:2822, cnt_2:411, acc:2013
INFO 2024-04-12 16:10:06,932 iter:1000, loss:1.7841721773147583, total_2:2822, cnt_2:411, acc:2082
INFO 2024-04-12 16:28:05,758 iter:2000, loss:1.8403276205062866, total_2:2822, cnt_2:411, acc:2045
INFO 2024-04-12 16:46:41,436 iter:3000, loss:1.8854355812072754, total_2:2822, cnt_2:411, acc:2049
INFO 2024-04-12 17:05:05,008 iter:4000, loss:1.8678125143051147, total_2:2822, cnt_2:411, acc:2086
INFO 2024-04-12 17:23:13,211 iter:5000, loss:1.8345186710357666, total_2:2822, cnt_2:411, acc:2073
INFO 2024-04-12 17:40:51,639 iter:6000, loss:1.8864504098892212, total_2:2822, cnt_2:411, acc:2034
INFO 2024-04-12 17:58:28,075 iter:7000, loss:1.8615895509719849, total_2:2822, cnt_2:411, acc:2015
INFO 2024-04-12 18:05:36,314 sss
INFO 2024-04-12 18:05:37,956 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-12 18:05:37,957 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp5izi79pk
INFO 2024-04-12 18:05:40,840 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-12 18:05:43,115 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-12 18:05:43,115 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-12 18:07:56,515 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-12 18:07:58,091 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-12 18:07:58,128 The size of dataset: train(34231), test(4926)
INFO 2024-04-12 18:07:58,128 Start training
INFO 2024-04-12 18:27:11,678 iter:1000, loss:2.1494863033294678, total_2:2302, cnt_2:395, acc:1478
INFO 2024-04-12 18:45:14,070 iter:2000, loss:1.9792910814285278, total_2:2302, cnt_2:395, acc:1746
INFO 2024-04-12 19:03:17,714 iter:3000, loss:1.9118140935897827, total_2:2302, cnt_2:395, acc:1845
INFO 2024-04-12 19:21:04,828 iter:4000, loss:1.8305202722549438, total_2:2302, cnt_2:395, acc:1891
INFO 2024-04-12 19:38:23,950 iter:5000, loss:1.8932381868362427, total_2:2302, cnt_2:395, acc:1916
INFO 2024-04-12 19:55:36,040 iter:6000, loss:1.7537405490875244, total_2:2302, cnt_2:395, acc:1900
INFO 2024-04-12 20:13:05,834 iter:7000, loss:1.804856538772583, total_2:2302, cnt_2:395, acc:1931
INFO 2024-04-12 21:07:42,653 iter:8000, loss:1.751756191253662, total_2:2302, cnt_2:395, acc:1979
INFO 2024-04-12 21:12:41,524 train_epoch:0, total_1:0, cnt_1:0, total_2:16259, cnt_2:3195
INFO 2024-04-12 21:21:54,775 epoch:0, loss:1.7874623537063599, total_2:2302, cnt_2:395, acc:2001
INFO 2024-04-12 21:42:43,296 iter:1000, loss:1.776850938796997, total_2:2302, cnt_2:395, acc:2004
INFO 2024-04-12 22:01:57,745 iter:2000, loss:1.7516270875930786, total_2:2302, cnt_2:395, acc:2031
INFO 2024-04-12 22:21:25,544 iter:3000, loss:1.7393568754196167, total_2:2302, cnt_2:395, acc:2040
INFO 2024-04-12 22:41:27,691 sss
INFO 2024-04-12 22:41:29,399 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-12 22:41:29,400 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpxqk9yfl3
INFO 2024-04-12 22:41:33,409 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-12 22:41:36,321 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-12 22:41:36,321 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-12 22:43:50,515 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-12 22:43:52,813 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-12 22:43:52,848 The size of dataset: train(34231), test(4926)
INFO 2024-04-12 22:43:52,848 Start training
INFO 2024-04-12 23:03:10,194 sss
INFO 2024-04-12 23:03:12,243 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-12 23:03:12,244 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpfm6mpwsf
INFO 2024-04-12 23:03:16,210 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-12 23:03:19,083 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-12 23:03:19,083 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-12 23:07:43,075 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-12 23:07:45,158 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-12 23:07:45,190 The size of dataset: train(34231), test(4926)
INFO 2024-04-12 23:07:45,190 Start training
INFO 2024-04-12 23:30:30,937 iter:1000, loss:2.126646041870117, total_2:4762, cnt_2:483, acc:1388
INFO 2024-04-12 23:52:14,730 iter:2000, loss:2.0322606563568115, total_2:4762, cnt_2:483, acc:1678
INFO 2024-04-13 00:12:50,912 iter:3000, loss:1.9272385835647583, total_2:4762, cnt_2:483, acc:1831
INFO 2024-04-13 00:33:26,024 iter:4000, loss:1.9164721965789795, total_2:4762, cnt_2:483, acc:1872
INFO 2024-04-13 00:54:03,756 iter:5000, loss:1.9029067754745483, total_2:4762, cnt_2:483, acc:1934
INFO 2024-04-13 01:15:22,133 iter:6000, loss:1.8685473203659058, total_2:4762, cnt_2:483, acc:1942
INFO 2024-04-13 01:35:32,809 iter:7000, loss:1.7862586975097656, total_2:4762, cnt_2:483, acc:1923
INFO 2024-04-13 01:55:58,142 iter:8000, loss:1.804013729095459, total_2:4762, cnt_2:483, acc:2004
INFO 2024-04-13 02:02:17,664 train_epoch:0, total_1:0, cnt_1:0, total_2:33069, cnt_2:3526
INFO 2024-04-13 02:12:10,972 epoch:0, loss:1.7976757287979126, total_2:4762, cnt_2:483, acc:2002
INFO 2024-04-13 02:34:30,557 iter:1000, loss:1.8275871276855469, total_2:4762, cnt_2:483, acc:1978
INFO 2024-04-13 02:55:27,158 iter:2000, loss:1.8230063915252686, total_2:4762, cnt_2:483, acc:2009
INFO 2024-04-13 03:16:25,699 iter:3000, loss:1.7743574380874634, total_2:4762, cnt_2:483, acc:2027
INFO 2024-04-13 03:37:01,105 iter:4000, loss:1.8154664039611816, total_2:4762, cnt_2:483, acc:2038
INFO 2024-04-13 03:57:37,852 iter:5000, loss:1.7553126811981201, total_2:4762, cnt_2:483, acc:2089
INFO 2024-04-13 10:19:28,007 sss
INFO 2024-04-13 10:19:29,436 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-13 10:19:29,439 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp8f3v_f4r
INFO 2024-04-13 10:19:33,298 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-13 10:19:36,535 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-13 10:19:36,536 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-13 10:21:50,157 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-13 10:21:51,853 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-13 10:21:51,924 The size of dataset: train(34231), test(4926)
INFO 2024-04-13 10:21:51,931 Start training
INFO 2024-04-13 10:44:47,353 sss
INFO 2024-04-13 10:44:48,418 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-13 10:44:48,418 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpfk00mq1x
INFO 2024-04-13 10:44:52,088 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-13 10:44:54,944 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-13 10:44:54,945 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-13 10:47:08,307 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-13 10:47:09,791 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-13 10:47:09,825 The size of dataset: train(34231), test(4926)
INFO 2024-04-13 10:47:09,826 Start training
INFO 2024-04-13 10:52:19,806 sss
INFO 2024-04-13 10:52:20,908 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-13 10:52:20,909 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp2uayzkrl
INFO 2024-04-13 10:52:23,972 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-13 10:52:26,161 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-13 10:52:26,161 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-13 10:54:39,877 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-13 10:54:41,605 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-13 10:54:41,636 The size of dataset: train(34231), test(4926)
INFO 2024-04-13 10:54:41,636 Start training
INFO 2024-04-13 11:05:00,935 sss
INFO 2024-04-13 11:05:02,207 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-13 11:05:02,208 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp__htk5pf
INFO 2024-04-13 11:05:05,477 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-13 11:05:08,014 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-13 11:05:08,014 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-13 11:07:21,783 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-13 11:07:23,334 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-13 11:07:23,442 The size of dataset: train(34231), test(4926)
INFO 2024-04-13 11:07:23,442 Start training
INFO 2024-04-13 11:14:07,299 sss
INFO 2024-04-13 11:14:08,672 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-13 11:14:08,673 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmppa8n3cgh
INFO 2024-04-13 11:14:13,009 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-13 11:14:17,091 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-13 11:14:17,091 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-13 11:16:31,658 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-13 11:16:33,462 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-13 11:16:33,549 The size of dataset: train(34231), test(4926)
INFO 2024-04-13 11:16:33,550 Start training
INFO 2024-04-13 11:56:19,384 sss
INFO 2024-04-13 11:56:20,836 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-13 11:56:20,837 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmppqrcpa66
INFO 2024-04-13 11:56:23,719 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-13 11:56:27,000 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-13 11:56:27,000 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-13 12:00:53,083 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-13 12:00:54,636 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-13 12:00:54,711 The size of dataset: train(34231), test(4926)
INFO 2024-04-13 12:00:54,712 Start training
INFO 2024-04-13 12:23:42,276 iter:1000, loss:2.2200615406036377, total_2:2822, cnt_2:411, acc:1261
INFO 2024-04-13 12:34:14,623 sss
INFO 2024-04-13 12:34:15,881 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-13 12:34:15,882 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpggupg9l1
INFO 2024-04-13 12:34:18,658 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-13 12:34:20,933 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-13 12:34:20,933 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-13 12:36:34,915 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-13 12:36:36,869 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-13 12:36:36,905 The size of dataset: train(34231), test(4926)
INFO 2024-04-13 12:36:36,905 Start training
INFO 2024-04-13 12:59:16,941 iter:1000, loss:2.1190884113311768, total_2:2822, cnt_2:362, acc:1499
INFO 2024-04-13 13:21:06,700 iter:2000, loss:1.9900637865066528, total_2:2822, cnt_2:362, acc:1738
INFO 2024-04-13 13:42:58,752 iter:3000, loss:2.0083811283111572, total_2:2822, cnt_2:362, acc:1818
INFO 2024-04-13 14:04:42,416 iter:4000, loss:1.8390717506408691, total_2:2822, cnt_2:362, acc:1867
INFO 2024-04-13 14:29:53,572 iter:5000, loss:1.9137804508209229, total_2:2822, cnt_2:362, acc:1889
INFO 2024-04-13 14:47:43,130 iter:6000, loss:1.8221534490585327, total_2:2822, cnt_2:362, acc:1920
INFO 2024-04-13 15:05:28,170 iter:7000, loss:1.8237794637680054, total_2:2822, cnt_2:362, acc:1919
INFO 2024-04-13 15:23:02,759 iter:8000, loss:1.813340663909912, total_2:2822, cnt_2:362, acc:1945
INFO 2024-04-13 15:28:17,945 train_epoch:0, total_1:0, cnt_1:0, total_2:19707, cnt_2:2994
INFO 2024-04-13 15:37:05,975 epoch:0, loss:1.7939579486846924, total_2:2822, cnt_2:362, acc:1985
INFO 2024-04-13 15:56:13,723 iter:1000, loss:1.7891367673873901, total_2:2822, cnt_2:362, acc:2004
INFO 2024-04-13 16:14:52,799 iter:2000, loss:1.760486125946045, total_2:2822, cnt_2:362, acc:2005
INFO 2024-04-13 16:32:46,405 iter:3000, loss:1.8080378770828247, total_2:2822, cnt_2:362, acc:2065
INFO 2024-04-13 16:52:10,343 iter:4000, loss:1.8322463035583496, total_2:2822, cnt_2:362, acc:2069
INFO 2024-04-13 17:10:07,624 iter:5000, loss:1.7754912376403809, total_2:2822, cnt_2:362, acc:2091
INFO 2024-04-13 17:27:48,403 iter:6000, loss:1.8306080102920532, total_2:2822, cnt_2:362, acc:2076
INFO 2024-04-13 17:45:42,399 iter:7000, loss:1.6926687955856323, total_2:2822, cnt_2:362, acc:2047
INFO 2024-04-13 18:03:13,654 iter:8000, loss:1.7852210998535156, total_2:2822, cnt_2:362, acc:2104
INFO 2024-04-13 18:08:18,791 train_epoch:1, total_1:0, cnt_1:0, total_2:19722, cnt_2:2996
INFO 2024-04-13 18:16:41,461 epoch:1, loss:1.7671006917953491, total_2:2822, cnt_2:362, acc:2090
INFO 2024-04-13 18:35:54,138 iter:1000, loss:1.8373464345932007, total_2:2822, cnt_2:362, acc:2027
INFO 2024-04-13 18:53:48,569 iter:2000, loss:1.7654194831848145, total_2:2822, cnt_2:362, acc:2079
INFO 2024-04-13 19:11:45,609 iter:3000, loss:1.8196117877960205, total_2:2822, cnt_2:362, acc:2094
INFO 2024-04-13 19:29:33,675 iter:4000, loss:1.7528599500656128, total_2:2822, cnt_2:362, acc:2080
INFO 2024-04-13 19:47:33,011 iter:5000, loss:1.744112491607666, total_2:2822, cnt_2:362, acc:2095
INFO 2024-04-13 20:05:16,702 iter:6000, loss:1.8109309673309326, total_2:2822, cnt_2:362, acc:2072
INFO 2024-04-13 20:23:11,575 iter:7000, loss:1.73695707321167, total_2:2822, cnt_2:362, acc:2090
INFO 2024-04-13 20:41:06,578 iter:8000, loss:1.6762360334396362, total_2:2822, cnt_2:362, acc:2072
INFO 2024-04-13 20:46:13,447 train_epoch:2, total_1:0, cnt_1:0, total_2:19693, cnt_2:2993
INFO 2024-04-13 20:54:38,162 epoch:2, loss:1.828122854232788, total_2:2822, cnt_2:362, acc:2073
INFO 2024-04-13 21:13:35,268 iter:1000, loss:1.7678782939910889, total_2:2822, cnt_2:362, acc:2053
INFO 2024-04-13 21:31:45,810 iter:2000, loss:1.7461256980895996, total_2:2822, cnt_2:362, acc:2101
INFO 2024-04-13 21:50:04,217 iter:3000, loss:1.7834995985031128, total_2:2822, cnt_2:362, acc:2066
INFO 2024-04-13 22:05:54,557 sss
INFO 2024-04-13 22:05:55,885 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-13 22:05:55,886 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp12h0mjfk
INFO 2024-04-13 22:05:58,426 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-13 22:06:00,505 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-13 22:06:00,505 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-13 22:08:13,724 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-13 22:08:15,253 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-13 22:08:15,288 The size of dataset: train(34231), test(4926)
INFO 2024-04-13 22:08:15,289 Start training
INFO 2024-04-13 22:14:37,498 sss
INFO 2024-04-13 22:14:39,090 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-13 22:14:39,091 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp7bftiu51
INFO 2024-04-13 22:14:41,606 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-13 22:14:43,574 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-13 22:14:43,575 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-13 22:16:56,728 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-13 22:16:58,477 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-13 22:16:58,516 The size of dataset: train(34231), test(4926)
INFO 2024-04-13 22:16:58,517 Start training
INFO 2024-04-13 22:22:16,381 sss
INFO 2024-04-13 22:22:17,736 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-13 22:22:17,737 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp78kcbx16
INFO 2024-04-13 22:22:20,255 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-13 22:22:22,206 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-13 22:22:22,206 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-13 22:24:35,263 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-13 22:24:36,590 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-13 22:24:36,626 The size of dataset: train(34231), test(4926)
INFO 2024-04-13 22:24:36,626 Start training
INFO 2024-04-13 22:30:11,212 sss
INFO 2024-04-13 22:30:12,361 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-13 22:30:12,362 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmprvxlt_sw
INFO 2024-04-13 22:30:14,877 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-13 22:30:16,818 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-13 22:30:16,818 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-13 22:32:29,947 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-13 22:32:31,396 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-13 22:32:31,432 The size of dataset: train(34231), test(4926)
INFO 2024-04-13 22:32:31,433 Start training
INFO 2024-04-13 22:44:28,518 sss
INFO 2024-04-13 22:44:29,945 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-13 22:44:29,946 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp2wkyzr4q
INFO 2024-04-13 22:44:32,473 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-13 22:44:34,529 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-13 22:44:34,529 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-13 22:44:40,356 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-13 22:44:41,963 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-13 22:44:41,998 The size of dataset: train(34231), test(4926)
INFO 2024-04-13 22:44:41,998 Start training
INFO 2024-04-13 22:52:04,926 sss
INFO 2024-04-13 22:52:06,115 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-13 22:52:06,116 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpc0a60io7
INFO 2024-04-13 22:52:08,632 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-13 22:52:10,633 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-13 22:52:10,633 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-13 22:54:23,554 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-13 22:54:25,951 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-13 22:54:25,986 The size of dataset: train(34231), test(4926)
INFO 2024-04-13 22:54:25,986 Start training
INFO 2024-04-13 23:08:28,066 sss
INFO 2024-04-13 23:08:29,476 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-13 23:08:29,477 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpgzwjcp6s
INFO 2024-04-13 23:08:31,996 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-13 23:08:34,014 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-13 23:08:34,014 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-13 23:10:47,313 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-13 23:10:48,777 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-13 23:10:48,813 The size of dataset: train(34231), test(4926)
INFO 2024-04-13 23:10:48,813 Start training
INFO 2024-04-13 23:16:29,982 sss
INFO 2024-04-13 23:16:31,248 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-13 23:16:31,249 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpopfui9g0
INFO 2024-04-13 23:16:33,767 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-13 23:16:35,732 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-13 23:16:35,732 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-13 23:18:49,140 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-13 23:18:50,552 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-13 23:18:50,588 The size of dataset: train(34231), test(4926)
INFO 2024-04-13 23:18:50,588 Start training
INFO 2024-04-13 23:27:29,404 sss
INFO 2024-04-13 23:27:30,858 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-13 23:27:30,859 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpfaz6p6zd
INFO 2024-04-13 23:27:33,388 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-13 23:27:35,332 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-13 23:27:35,332 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-13 23:29:48,752 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-13 23:29:50,102 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-13 23:29:50,137 The size of dataset: train(34231), test(4926)
INFO 2024-04-13 23:29:50,137 Start training
INFO 2024-04-13 23:40:05,555 sss
INFO 2024-04-13 23:40:06,726 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-13 23:40:06,727 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp5hv0784a
INFO 2024-04-13 23:40:09,245 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-13 23:40:11,216 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-13 23:40:11,216 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-13 23:42:24,626 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-13 23:42:26,603 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-13 23:42:26,638 The size of dataset: train(34231), test(4926)
INFO 2024-04-13 23:42:26,638 Start training
INFO 2024-04-13 23:51:25,081 sss
INFO 2024-04-13 23:51:26,258 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-13 23:51:26,259 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpgv30uhxj
INFO 2024-04-13 23:51:28,793 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-13 23:51:30,745 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-13 23:51:30,745 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-13 23:53:47,828 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-13 23:53:49,381 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-13 23:53:49,417 The size of dataset: train(34231), test(4926)
INFO 2024-04-13 23:53:49,418 Start training
INFO 2024-04-14 00:06:51,041 iter:0, loss:3.6431500911712646, total_2:2822, cnt_2:453, acc:628
INFO 2024-04-14 00:10:45,780 sss
INFO 2024-04-14 00:10:46,956 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-14 00:10:46,957 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpein_03mv
INFO 2024-04-14 00:10:49,613 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-14 00:10:51,760 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-14 00:10:51,760 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-14 00:13:04,789 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-14 00:13:06,549 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-14 00:13:06,587 The size of dataset: train(34231), test(4926)
INFO 2024-04-14 00:13:06,587 Start training
INFO 2024-04-14 00:34:06,079 iter:1000, loss:2.2596001625061035, total_2:2822, cnt_2:471, acc:1397
INFO 2024-04-14 00:54:31,658 iter:2000, loss:2.0240018367767334, total_2:2822, cnt_2:471, acc:1699
INFO 2024-04-14 01:14:22,843 iter:3000, loss:2.0334384441375732, total_2:2822, cnt_2:471, acc:1790
INFO 2024-04-14 01:34:03,831 iter:4000, loss:1.8378809690475464, total_2:2822, cnt_2:471, acc:1783
INFO 2024-04-14 01:53:43,805 iter:5000, loss:1.8228963613510132, total_2:2822, cnt_2:471, acc:1869
INFO 2024-04-14 02:13:08,307 iter:6000, loss:1.8262596130371094, total_2:2822, cnt_2:471, acc:1943
INFO 2024-04-14 02:32:38,208 iter:7000, loss:1.8558781147003174, total_2:2822, cnt_2:471, acc:2008
INFO 2024-04-14 02:52:18,182 iter:8000, loss:1.8211495876312256, total_2:2822, cnt_2:471, acc:2012
INFO 2024-04-14 03:11:40,383 iter:9000, loss:1.8060322999954224, total_2:2822, cnt_2:471, acc:2021
INFO 2024-04-14 03:31:21,799 iter:10000, loss:1.8094221353530884, total_2:2822, cnt_2:471, acc:2036
INFO 2024-04-14 03:50:36,911 iter:11000, loss:1.7358129024505615, total_2:2822, cnt_2:471, acc:2054
INFO 2024-04-14 04:10:03,122 iter:12000, loss:1.758847951889038, total_2:2822, cnt_2:471, acc:2041
INFO 2024-04-14 04:29:44,057 iter:13000, loss:1.752384901046753, total_2:2822, cnt_2:471, acc:2037
INFO 2024-04-14 04:49:13,376 iter:14000, loss:1.7557220458984375, total_2:2822, cnt_2:471, acc:2061
INFO 2024-04-14 05:08:37,903 iter:15000, loss:1.7311111688613892, total_2:2822, cnt_2:471, acc:2104
INFO 2024-04-14 05:28:24,760 iter:16000, loss:1.7795192003250122, total_2:2822, cnt_2:471, acc:2016
INFO 2024-04-14 05:47:45,051 iter:17000, loss:1.7553707361221313, total_2:2822, cnt_2:471, acc:2128
INFO 2024-04-14 05:48:45,048 train_epoch:0, total_1:0, cnt_1:0, total_2:19710, cnt_2:3686
INFO 2024-04-14 05:59:32,126 epoch:0, loss:1.6841083765029907, total_2:2822, cnt_2:471, acc:2095
INFO 2024-04-14 06:19:56,622 iter:1000, loss:1.7238224744796753, total_2:2822, cnt_2:471, acc:2087
INFO 2024-04-14 06:39:35,588 iter:2000, loss:1.787055492401123, total_2:2822, cnt_2:471, acc:2066
INFO 2024-04-14 06:59:16,156 iter:3000, loss:1.7067339420318604, total_2:2822, cnt_2:471, acc:2099
INFO 2024-04-14 07:18:37,612 iter:4000, loss:1.7057570219039917, total_2:2822, cnt_2:471, acc:2107
INFO 2024-04-14 07:38:43,894 iter:5000, loss:1.7332602739334106, total_2:2822, cnt_2:471, acc:2114
INFO 2024-04-14 07:57:41,654 iter:6000, loss:1.728459119796753, total_2:2822, cnt_2:471, acc:2109
INFO 2024-04-14 08:17:14,613 iter:7000, loss:1.6360751390457153, total_2:2822, cnt_2:471, acc:2133
INFO 2024-04-14 08:36:55,646 iter:8000, loss:1.696075201034546, total_2:2822, cnt_2:471, acc:2119
INFO 2024-04-14 08:56:37,203 iter:9000, loss:1.6866912841796875, total_2:2822, cnt_2:471, acc:2140
INFO 2024-04-14 09:15:56,723 iter:10000, loss:1.7648416757583618, total_2:2822, cnt_2:471, acc:2167
INFO 2024-04-14 09:35:17,153 iter:11000, loss:1.7460503578186035, total_2:2822, cnt_2:471, acc:2128
INFO 2024-04-14 09:53:53,309 iter:12000, loss:1.665571689605713, total_2:2822, cnt_2:471, acc:2155
INFO 2024-04-14 10:13:19,368 iter:13000, loss:1.6796250343322754, total_2:2822, cnt_2:471, acc:2144
INFO 2024-04-14 10:32:42,675 iter:14000, loss:1.6882179975509644, total_2:2822, cnt_2:471, acc:2147
INFO 2024-04-14 10:52:02,203 iter:15000, loss:1.7087453603744507, total_2:2822, cnt_2:471, acc:2167
INFO 2024-04-14 11:11:36,536 iter:16000, loss:1.7031244039535522, total_2:2822, cnt_2:471, acc:2148
INFO 2024-04-14 11:30:55,581 iter:17000, loss:1.677755355834961, total_2:2822, cnt_2:471, acc:2182
INFO 2024-04-14 11:31:55,846 train_epoch:1, total_1:0, cnt_1:0, total_2:19743, cnt_2:3679
INFO 2024-04-14 11:42:32,186 epoch:1, loss:1.7046290636062622, total_2:2822, cnt_2:471, acc:2174
INFO 2024-04-14 12:02:56,644 iter:1000, loss:1.6925336122512817, total_2:2822, cnt_2:471, acc:2138
INFO 2024-04-14 12:22:39,702 iter:2000, loss:1.6922239065170288, total_2:2822, cnt_2:471, acc:2176
INFO 2024-04-14 12:42:11,203 iter:3000, loss:1.626760482788086, total_2:2822, cnt_2:471, acc:2165
INFO 2024-04-14 13:01:04,398 iter:4000, loss:1.6544735431671143, total_2:2822, cnt_2:471, acc:2194    this one
INFO 2024-04-14 16:42:08,440 sss
INFO 2024-04-14 16:42:10,025 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-14 16:42:10,026 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpowyw94ed
INFO 2024-04-14 16:42:12,691 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}
TextVQA + MultiheadAttention + Binary
INFO 2024-04-14 16:42:35,187 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-14 16:42:35,187 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-14 16:44:48,792 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-14 16:44:50,363 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-14 16:44:50,398 The size of dataset: train(34231), test(4926)
INFO 2024-04-14 16:44:50,398 Start training
INFO 2024-04-14 17:06:31,085 iter:1000, loss:2.1206188201904297, total_2:2822, cnt_2:471, acc:1608
INFO 2024-04-14 17:27:14,955 iter:2000, loss:1.9787653684616089, total_2:2822, cnt_2:471, acc:1752
INFO 2024-04-14 17:47:38,620 iter:3000, loss:1.973802089691162, total_2:2822, cnt_2:471, acc:1792
INFO 2024-04-14 18:08:12,432 iter:4000, loss:1.9042049646377563, total_2:2822, cnt_2:471, acc:1816
INFO 2024-04-14 18:28:48,577 iter:5000, loss:1.8244467973709106, total_2:2822, cnt_2:471, acc:1872
INFO 2024-04-14 18:48:58,870 iter:6000, loss:1.7746659517288208, total_2:2822, cnt_2:471, acc:1995
INFO 2024-04-14 19:09:28,121 iter:7000, loss:1.8170316219329834, total_2:2822, cnt_2:471, acc:1982
INFO 2024-04-14 19:30:16,946 iter:8000, loss:1.8539748191833496, total_2:2822, cnt_2:471, acc:1962
INFO 2024-04-14 19:51:00,477 iter:9000, loss:1.8027933835983276, total_2:2822, cnt_2:471, acc:2038
INFO 2024-04-14 20:27:34,773 iter:10000, loss:1.7474884986877441, total_2:2822, cnt_2:471, acc:2035
INFO 2024-04-14 20:47:13,088 iter:11000, loss:1.7532013654708862, total_2:2822, cnt_2:471, acc:2011
INFO 2024-04-14 21:07:01,388 iter:12000, loss:1.71258544921875, total_2:2822, cnt_2:471, acc:2055
INFO 2024-04-14 21:27:48,371 iter:13000, loss:1.812821865081787, total_2:2822, cnt_2:471, acc:2038
INFO 2024-04-14 21:48:57,298 iter:14000, loss:1.7590928077697754, total_2:2822, cnt_2:471, acc:2074
INFO 2024-04-14 22:09:06,569 iter:15000, loss:1.7518794536590576, total_2:2822, cnt_2:471, acc:2087
INFO 2024-04-14 22:29:03,338 iter:16000, loss:1.780959129333496, total_2:2822, cnt_2:471, acc:2093
INFO 2024-04-14 22:48:59,482 iter:17000, loss:1.7147676944732666, total_2:2822, cnt_2:471, acc:2143
INFO 2024-04-14 22:50:06,448 train_epoch:0, total_1:0, cnt_1:0, total_2:19739, cnt_2:3682
INFO 2024-04-14 23:01:06,478 epoch:0, loss:1.7310703992843628, total_2:2822, cnt_2:471, acc:2133
INFO 2024-04-14 23:22:09,876 iter:1000, loss:1.724257230758667, total_2:2822, cnt_2:471, acc:2116
INFO 2024-04-14 23:42:27,365 iter:2000, loss:1.709346055984497, total_2:2822, cnt_2:471, acc:2109
INFO 2024-04-15 00:02:28,638 iter:3000, loss:1.7030214071273804, total_2:2822, cnt_2:471, acc:2131
INFO 2024-04-15 00:22:32,850 iter:4000, loss:1.7161266803741455, total_2:2822, cnt_2:471, acc:2144
INFO 2024-04-15 00:42:50,502 iter:5000, loss:1.7245720624923706, total_2:2822, cnt_2:471, acc:2122
INFO 2024-04-15 01:03:05,550 iter:6000, loss:1.6876698732376099, total_2:2822, cnt_2:471, acc:2145
INFO 2024-04-15 01:23:30,266 iter:7000, loss:1.652217984199524, total_2:2822, cnt_2:471, acc:2148
INFO 2024-04-15 01:44:01,567 iter:8000, loss:1.7182745933532715, total_2:2822, cnt_2:471, acc:2118
INFO 2024-04-15 02:04:02,112 iter:9000, loss:1.7141777276992798, total_2:2822, cnt_2:471, acc:2146
INFO 2024-04-15 02:24:15,958 iter:10000, loss:1.7100456953048706, total_2:2822, cnt_2:471, acc:2174
INFO 2024-04-15 02:44:23,444 iter:11000, loss:1.6900099515914917, total_2:2822, cnt_2:471, acc:2124
INFO 2024-04-15 03:04:21,362 iter:12000, loss:1.7454819679260254, total_2:2822, cnt_2:471, acc:2149
INFO 2024-04-15 03:24:47,211 iter:13000, loss:1.7201811075210571, total_2:2822, cnt_2:471, acc:2142
INFO 2024-04-15 03:44:51,428 iter:14000, loss:1.7134214639663696, total_2:2822, cnt_2:471, acc:2143
INFO 2024-04-15 04:04:32,829 iter:15000, loss:1.7098532915115356, total_2:2822, cnt_2:471, acc:2164
INFO 2024-04-15 04:24:34,325 iter:16000, loss:1.7523599863052368, total_2:2822, cnt_2:471, acc:2157
INFO 2024-04-15 04:45:11,259 iter:17000, loss:1.7056316137313843, total_2:2822, cnt_2:471, acc:2179
INFO 2024-04-15 04:46:16,967 train_epoch:1, total_1:0, cnt_1:0, total_2:19728, cnt_2:3680
INFO 2024-04-15 04:57:08,090 epoch:1, loss:1.6720060110092163, total_2:2822, cnt_2:471, acc:2177
INFO 2024-04-15 05:18:27,725 iter:1000, loss:1.7358371019363403, total_2:2822, cnt_2:471, acc:2141
INFO 2024-04-15 05:38:39,466 iter:2000, loss:1.6591936349868774, total_2:2822, cnt_2:471, acc:2112
INFO 2024-04-15 05:58:27,335 iter:3000, loss:1.7749131917953491, total_2:2822, cnt_2:471, acc:2167
INFO 2024-04-15 06:17:59,436 iter:4000, loss:1.6761082410812378, total_2:2822, cnt_2:471, acc:2175
INFO 2024-04-15 06:37:20,064 iter:5000, loss:1.6905511617660522, total_2:2822, cnt_2:471, acc:2177
INFO 2024-04-15 06:56:48,616 iter:6000, loss:1.6470414400100708, total_2:2822, cnt_2:471, acc:2141
INFO 2024-04-15 07:16:07,391 iter:7000, loss:1.7134324312210083, total_2:2822, cnt_2:471, acc:2175
INFO 2024-04-15 07:35:40,822 iter:8000, loss:1.69456148147583, total_2:2822, cnt_2:471, acc:2156
INFO 2024-04-15 07:55:03,013 iter:9000, loss:1.7344156503677368, total_2:2822, cnt_2:471, acc:2156
INFO 2024-04-15 08:14:24,591 iter:10000, loss:1.6791561841964722, total_2:2822, cnt_2:471, acc:2140
INFO 2024-04-15 08:33:42,525 iter:11000, loss:1.7316945791244507, total_2:2822, cnt_2:471, acc:2124
INFO 2024-04-15 08:53:01,457 iter:12000, loss:1.7020372152328491, total_2:2822, cnt_2:471, acc:2155
INFO 2024-04-15 09:29:12,582 iter:13000, loss:1.7920230627059937, total_2:2822, cnt_2:471, acc:2166
INFO 2024-04-15 09:48:50,282 iter:14000, loss:1.6626126766204834, total_2:2822, cnt_2:471, acc:2145
INFO 2024-04-15 10:10:57,860 iter:15000, loss:1.6499520540237427, total_2:2822, cnt_2:471, acc:2146
INFO 2024-04-15 10:32:19,791 iter:16000, loss:1.6617294549942017, total_2:2822, cnt_2:471, acc:2196   
INFO 2024-04-15 10:53:55,002 iter:17000, loss:1.7082852125167847, total_2:2822, cnt_2:471, acc:2185
INFO 2024-04-15 10:54:59,016 train_epoch:2, total_1:0, cnt_1:0, total_2:19725, cnt_2:3678
INFO 2024-04-15 11:05:45,614 epoch:2, loss:1.6904704570770264, total_2:2822, cnt_2:471, acc:2192
INFO 2024-04-15 11:26:33,727 iter:1000, loss:1.7235945463180542, total_2:2822, cnt_2:471, acc:2120
INFO 2024-04-15 11:47:08,465 iter:2000, loss:1.751884937286377, total_2:2822, cnt_2:471, acc:2123
INFO 2024-04-15 12:06:41,812 iter:3000, loss:1.7605704069137573, total_2:2822, cnt_2:471, acc:2170
INFO 2024-04-15 12:26:29,269 iter:4000, loss:1.7073415517807007, total_2:2822, cnt_2:471, acc:2143
INFO 2024-04-15 12:46:08,081 iter:5000, loss:1.7094316482543945, total_2:2822, cnt_2:471, acc:2152
INFO 2024-04-15 13:05:47,621 iter:6000, loss:1.7116495370864868, total_2:2822, cnt_2:471, acc:2157
INFO 2024-04-15 13:26:00,025 iter:7000, loss:1.810401439666748, total_2:2822, cnt_2:471, acc:2144
INFO 2024-04-15 13:45:42,381 iter:8000, loss:1.7071685791015625, total_2:2822, cnt_2:471, acc:2223 this one!
INFO 2024-04-15 14:05:30,281 iter:9000, loss:1.7031370401382446, total_2:2822, cnt_2:471, acc:2166
INFO 2024-04-15 14:25:25,867 iter:10000, loss:1.7759238481521606, total_2:2822, cnt_2:471, acc:2172
INFO 2024-04-15 14:51:23,629 iter:11000, loss:1.7369352579116821, total_2:2822, cnt_2:471, acc:2104
INFO 2024-04-15 15:19:36,682 iter:12000, loss:1.7654268741607666, total_2:2822, cnt_2:471, acc:2152
INFO 2024-04-15 15:40:27,671 iter:13000, loss:1.7875584363937378, total_2:2822, cnt_2:471, acc:2137
INFO 2024-04-15 16:01:01,036 iter:14000, loss:1.7348880767822266, total_2:2822, cnt_2:471, acc:2157
INFO 2024-04-15 16:22:00,544 iter:15000, loss:1.746994972229004, total_2:2822, cnt_2:471, acc:2151
INFO 2024-04-15 16:48:18,366 iter:16000, loss:1.755767822265625, total_2:2822, cnt_2:471, acc:2160
INFO 2024-04-15 17:09:21,436 iter:17000, loss:1.7348862886428833, total_2:2822, cnt_2:471, acc:2169
INFO 2024-04-15 17:10:25,821 train_epoch:3, total_1:0, cnt_1:0, total_2:19721, cnt_2:3674
INFO 2024-04-15 17:22:38,552 epoch:3, loss:1.7433854341506958, total_2:2822, cnt_2:471, acc:2161
INFO 2024-04-15 17:44:34,020 iter:1000, loss:1.7643049955368042, total_2:2822, cnt_2:471, acc:2125
INFO 2024-04-15 18:06:57,601 iter:2000, loss:1.776015043258667, total_2:2822, cnt_2:471, acc:2138
INFO 2024-04-15 18:47:41,070 iter:3000, loss:1.7715630531311035, total_2:2822, cnt_2:471, acc:2126
INFO 2024-04-15 19:10:05,507 iter:4000, loss:1.7966948747634888, total_2:2822, cnt_2:471, acc:2148
INFO 2024-04-15 19:32:10,173 iter:5000, loss:1.7471235990524292, total_2:2822, cnt_2:471, acc:2145
INFO 2024-04-15 19:54:00,515 iter:6000, loss:1.7782186269760132, total_2:2822, cnt_2:471, acc:2178
INFO 2024-04-15 20:15:16,182 iter:7000, loss:1.7516318559646606, total_2:2822, cnt_2:471, acc:2162
INFO 2024-04-15 20:36:42,240 iter:8000, loss:1.6976590156555176, total_2:2822, cnt_2:471, acc:2144
INFO 2024-04-15 20:58:41,588 iter:9000, loss:1.7728828191757202, total_2:2822, cnt_2:471, acc:2165
INFO 2024-04-15 21:20:40,510 iter:10000, loss:1.7532973289489746, total_2:2822, cnt_2:471, acc:2170
INFO 2024-04-15 21:42:42,574 iter:11000, loss:1.7910237312316895, total_2:2822, cnt_2:471, acc:2162
INFO 2024-04-15 22:04:57,380 iter:12000, loss:1.8055419921875, total_2:2822, cnt_2:471, acc:2129
INFO 2024-04-15 22:26:52,982 iter:13000, loss:1.7329490184783936, total_2:2822, cnt_2:471, acc:2154
INFO 2024-04-15 22:37:06,121 sss
INFO 2024-04-15 22:37:07,219 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-15 22:37:07,220 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpwmfyxy9i
INFO 2024-04-15 22:37:09,979 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}
without Binary
INFO 2024-04-15 22:37:12,183 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-15 22:37:12,183 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-15 22:39:25,552 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-15 22:42:55,715 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-15 22:42:55,756 The size of dataset: train(34231), test(4926)
INFO 2024-04-15 22:42:55,757 Start training
INFO 2024-04-15 23:05:06,731 iter:1000, loss:2.3120791912078857, total_2:4762, cnt_2:585, acc:1332
INFO 2024-04-15 23:31:37,827 iter:2000, loss:2.0598409175872803, total_2:4762, cnt_2:585, acc:1545
INFO 2024-04-15 23:53:07,045 iter:3000, loss:2.017632246017456, total_2:4762, cnt_2:585, acc:1746
INFO 2024-04-16 00:14:01,778 iter:4000, loss:1.9017384052276611, total_2:4762, cnt_2:585, acc:1817
INFO 2024-04-16 00:35:01,904 iter:5000, loss:1.858173131942749, total_2:4762, cnt_2:585, acc:1875
INFO 2024-04-16 01:00:31,554 iter:6000, loss:1.8675016164779663, total_2:4762, cnt_2:585, acc:1959
INFO 2024-04-16 01:21:09,037 iter:7000, loss:1.786515474319458, total_2:4762, cnt_2:585, acc:1991
INFO 2024-04-16 01:41:53,752 iter:8000, loss:1.7791117429733276, total_2:4762, cnt_2:585, acc:1970
INFO 2024-04-16 02:02:28,040 iter:9000, loss:1.7850533723831177, total_2:4762, cnt_2:585, acc:2046
INFO 2024-04-16 02:22:28,729 iter:10000, loss:1.8180813789367676, total_2:4762, cnt_2:585, acc:2037
INFO 2024-04-16 02:42:23,548 iter:11000, loss:1.7591845989227295, total_2:4762, cnt_2:585, acc:2026
INFO 2024-04-16 03:02:27,970 iter:12000, loss:1.7966583967208862, total_2:4762, cnt_2:585, acc:1977
INFO 2024-04-16 03:22:35,327 iter:13000, loss:1.7930177450180054, total_2:4762, cnt_2:585, acc:2066
INFO 2024-04-16 03:42:33,753 iter:14000, loss:1.7062859535217285, total_2:4762, cnt_2:585, acc:2063
INFO 2024-04-16 04:02:31,637 iter:15000, loss:1.6783360242843628, total_2:4762, cnt_2:585, acc:2085
INFO 2024-04-16 04:22:39,793 iter:16000, loss:1.7300583124160767, total_2:4762, cnt_2:585, acc:2050
INFO 2024-04-16 04:42:47,418 iter:17000, loss:1.759962558746338, total_2:4762, cnt_2:585, acc:2104
INFO 2024-04-16 04:43:49,807 train_epoch:0, total_1:0, cnt_1:0, total_2:33071, cnt_2:4297
INFO 2024-04-16 04:54:40,916 epoch:0, loss:1.715127944946289, total_2:4762, cnt_2:585, acc:2100
INFO 2024-04-16 05:15:40,646 iter:1000, loss:1.7167118787765503, total_2:4762, cnt_2:585, acc:2090
INFO 2024-04-16 05:36:04,470 iter:2000, loss:1.7160674333572388, total_2:4762, cnt_2:585, acc:2096
INFO 2024-04-16 05:56:16,643 iter:3000, loss:1.7534772157669067, total_2:4762, cnt_2:585, acc:2104
INFO 2024-04-16 06:16:20,024 iter:4000, loss:1.7661170959472656, total_2:4762, cnt_2:585, acc:2126
INFO 2024-04-16 06:36:26,985 iter:5000, loss:1.67582368850708, total_2:4762, cnt_2:585, acc:2144
INFO 2024-04-16 06:56:09,924 iter:6000, loss:1.7068358659744263, total_2:4762, cnt_2:585, acc:2134
INFO 2024-04-16 07:16:06,417 iter:7000, loss:1.7777961492538452, total_2:4762, cnt_2:585, acc:2174
INFO 2024-04-16 07:36:28,107 iter:8000, loss:1.6850801706314087, total_2:4762, cnt_2:585, acc:2136
INFO 2024-04-16 07:56:38,548 iter:9000, loss:1.7632396221160889, total_2:4762, cnt_2:585, acc:2149
INFO 2024-04-16 08:17:01,609 iter:10000, loss:1.7042192220687866, total_2:4762, cnt_2:585, acc:2179
INFO 2024-04-16 08:36:57,540 iter:11000, loss:1.7144242525100708, total_2:4762, cnt_2:585, acc:2136
INFO 2024-04-16 08:56:57,031 iter:12000, loss:1.7251466512680054, total_2:4762, cnt_2:585, acc:2152
INFO 2024-04-16 09:16:58,289 iter:13000, loss:1.686807632446289, total_2:4762, cnt_2:585, acc:2109
INFO 2024-04-16 09:37:20,050 iter:14000, loss:1.6504732370376587, total_2:4762, cnt_2:585, acc:2145
INFO 2024-04-16 09:57:26,884 iter:15000, loss:1.6785104274749756, total_2:4762, cnt_2:585, acc:2124
INFO 2024-04-16 10:17:35,185 iter:16000, loss:1.72829008102417, total_2:4762, cnt_2:585, acc:2119
INFO 2024-04-16 10:37:40,830 iter:17000, loss:1.6261155605316162, total_2:4762, cnt_2:585, acc:2150
INFO 2024-04-16 10:38:43,634 train_epoch:1, total_1:0, cnt_1:0, total_2:33071, cnt_2:4298
INFO 2024-04-16 10:49:51,281 epoch:1, loss:1.6958714723587036, total_2:4762, cnt_2:585, acc:2154
INFO 2024-04-16 11:11:09,904 iter:1000, loss:1.7396060228347778, total_2:4762, cnt_2:585, acc:2126
INFO 2024-04-16 11:31:02,761 iter:2000, loss:1.7042033672332764, total_2:4762, cnt_2:585, acc:2178
INFO 2024-04-16 11:51:26,254 iter:3000, loss:1.7013636827468872, total_2:4762, cnt_2:585, acc:2154
INFO 2024-04-16 12:12:08,436 iter:4000, loss:1.6481242179870605, total_2:4762, cnt_2:585, acc:2138
INFO 2024-04-16 12:35:28,661 iter:5000, loss:1.6825224161148071, total_2:4762, cnt_2:585, acc:2161
INFO 2024-04-16 12:56:29,918 iter:6000, loss:1.6848677396774292, total_2:4762, cnt_2:585, acc:2167
INFO 2024-04-16 13:18:35,242 iter:7000, loss:1.7437788248062134, total_2:4762, cnt_2:585, acc:2180
INFO 2024-04-16 13:41:58,984 iter:8000, loss:1.6634513139724731, total_2:4762, cnt_2:585, acc:2166
INFO 2024-04-16 14:04:56,473 iter:9000, loss:1.6979591846466064, total_2:4762, cnt_2:585, acc:2176
INFO 2024-04-16 14:27:48,556 iter:10000, loss:1.6758668422698975, total_2:4762, cnt_2:585, acc:2177
INFO 2024-04-16 14:50:50,363 iter:11000, loss:1.7762906551361084, total_2:4762, cnt_2:585, acc:2152
INFO 2024-04-16 15:14:02,234 iter:12000, loss:1.6709685325622559, total_2:4762, cnt_2:585, acc:2163
INFO 2024-04-16 15:37:32,776 iter:13000, loss:1.6248877048492432, total_2:4762, cnt_2:585, acc:2144
INFO 2024-04-16 16:00:07,346 iter:14000, loss:1.716813564300537, total_2:4762, cnt_2:585, acc:2151
INFO 2024-04-16 16:22:12,864 iter:15000, loss:1.6926122903823853, total_2:4762, cnt_2:585, acc:2167
INFO 2024-04-16 16:45:24,043 iter:16000, loss:1.7598838806152344, total_2:4762, cnt_2:585, acc:2133
INFO 2024-04-16 17:17:16,003 sss
INFO 2024-04-16 17:17:18,103 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-16 17:17:18,104 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmps9ysm7i7
INFO 2024-04-16 17:17:21,132 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-16 17:17:36,520 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-16 17:17:36,521 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-16 17:19:53,281 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-16 17:19:54,783 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-16 17:19:54,822 The size of dataset: train(34231), test(4926)
INFO 2024-04-16 17:19:54,823 Start training
INFO 2024-04-16 17:43:51,503 iter:1000, loss:2.0565783977508545, total_2:2822, cnt_2:423, acc:1617
INFO 2024-04-16 18:07:40,105 iter:2000, loss:1.9897472858428955, total_2:2822, cnt_2:423, acc:1712
INFO 2024-04-16 18:30:56,016 iter:3000, loss:1.9742764234542847, total_2:2822, cnt_2:423, acc:1811
INFO 2024-04-16 18:53:55,162 iter:4000, loss:1.8722337484359741, total_2:2822, cnt_2:423, acc:1827
INFO 2024-04-16 19:16:39,263 iter:5000, loss:1.9970930814743042, total_2:2822, cnt_2:423, acc:1906
INFO 2024-04-16 19:39:24,306 iter:6000, loss:1.771047830581665, total_2:2822, cnt_2:423, acc:1969
INFO 2024-04-16 20:15:02,979 iter:7000, loss:1.7854135036468506, total_2:2822, cnt_2:423, acc:2011
INFO 2024-04-16 20:43:32,083 iter:8000, loss:1.7657676935195923, total_2:2822, cnt_2:423, acc:2020
INFO 2024-04-16 21:06:29,161 iter:9000, loss:1.7513059377670288, total_2:2822, cnt_2:423, acc:2068
INFO 2024-04-16 21:28:56,451 iter:10000, loss:1.7480605840682983, total_2:2822, cnt_2:423, acc:2054
INFO 2024-04-16 21:51:01,769 iter:11000, loss:1.8026703596115112, total_2:2822, cnt_2:423, acc:1995
INFO 2024-04-16 22:13:24,751 iter:12000, loss:1.7650320529937744, total_2:2822, cnt_2:423, acc:2039
INFO 2024-04-16 22:36:01,131 iter:13000, loss:1.7756670713424683, total_2:2822, cnt_2:423, acc:2038
INFO 2024-04-16 22:58:17,537 iter:14000, loss:1.7171543836593628, total_2:2822, cnt_2:423, acc:2052
INFO 2024-04-16 23:20:47,955 iter:15000, loss:1.702484130859375, total_2:2822, cnt_2:423, acc:2072
INFO 2024-04-16 23:43:17,053 iter:16000, loss:1.6950435638427734, total_2:2822, cnt_2:423, acc:2060
INFO 2024-04-17 00:05:34,822 iter:17000, loss:1.7229387760162354, total_2:2822, cnt_2:423, acc:2118
INFO 2024-04-17 00:06:46,962 train_epoch:0, total_1:0, cnt_1:0, total_2:19733, cnt_2:3377
INFO 2024-04-17 00:18:45,704 epoch:0, loss:1.6817845106124878, total_2:2822, cnt_2:423, acc:2116
INFO 2024-04-17 00:42:08,854 iter:1000, loss:1.6828532218933105, total_2:2822, cnt_2:423, acc:2099
INFO 2024-04-17 01:04:49,037 iter:2000, loss:1.7425029277801514, total_2:2822, cnt_2:423, acc:2093
INFO 2024-04-17 01:27:30,638 iter:3000, loss:1.709667444229126, total_2:2822, cnt_2:423, acc:2113
INFO 2024-04-17 01:49:48,395 iter:4000, loss:1.670456886291504, total_2:2822, cnt_2:423, acc:2114
INFO 2024-04-17 02:12:26,108 iter:5000, loss:1.7304420471191406, total_2:2822, cnt_2:423, acc:2124
INFO 2024-04-17 02:34:47,676 iter:6000, loss:1.7641205787658691, total_2:2822, cnt_2:423, acc:2168
INFO 2024-04-17 02:56:55,766 iter:7000, loss:1.7320047616958618, total_2:2822, cnt_2:423, acc:2135
INFO 2024-04-17 03:19:28,280 iter:8000, loss:1.7275761365890503, total_2:2822, cnt_2:423, acc:2146
INFO 2024-04-17 03:42:05,661 iter:9000, loss:1.668285846710205, total_2:2822, cnt_2:423, acc:2152
INFO 2024-04-17 04:04:02,925 iter:10000, loss:1.7069495916366577, total_2:2822, cnt_2:423, acc:2160
INFO 2024-04-17 04:26:14,195 iter:11000, loss:1.6886875629425049, total_2:2822, cnt_2:423, acc:2144
INFO 2024-04-17 04:48:32,529 iter:12000, loss:1.70823335647583, total_2:2822, cnt_2:423, acc:2150
INFO 2024-04-17 05:10:08,169 iter:13000, loss:1.7274465560913086, total_2:2822, cnt_2:423, acc:2073
INFO 2024-04-17 05:32:42,983 iter:14000, loss:1.693272590637207, total_2:2822, cnt_2:423, acc:2085
INFO 2024-04-17 05:55:06,369 iter:15000, loss:1.723710298538208, total_2:2822, cnt_2:423, acc:2153
INFO 2024-04-17 06:17:40,643 iter:16000, loss:1.6815460920333862, total_2:2822, cnt_2:423, acc:2135
INFO 2024-04-17 06:40:10,012 iter:17000, loss:1.7461044788360596, total_2:2822, cnt_2:423, acc:2190
INFO 2024-04-17 06:41:21,530 train_epoch:1, total_1:0, cnt_1:0, total_2:19731, cnt_2:3362
INFO 2024-04-17 06:53:11,148 epoch:1, loss:1.7110179662704468, total_2:2822, cnt_2:423, acc:2178
INFO 2024-04-17 07:16:49,117 iter:1000, loss:1.7304729223251343, total_2:2822, cnt_2:423, acc:2167
INFO 2024-04-17 07:38:52,570 iter:2000, loss:1.727022409439087, total_2:2822, cnt_2:423, acc:2114
INFO 2024-04-17 07:59:17,492 iter:3000, loss:1.6859396696090698, total_2:2822, cnt_2:423, acc:2170
INFO 2024-04-17 08:19:54,780 iter:4000, loss:1.6652841567993164, total_2:2822, cnt_2:423, acc:2155
INFO 2024-04-17 08:40:49,056 iter:5000, loss:1.666208028793335, total_2:2822, cnt_2:423, acc:2191
INFO 2024-04-17 09:01:28,182 iter:6000, loss:1.7099289894104004, total_2:2822, cnt_2:423, acc:2145
INFO 2024-04-17 09:22:12,844 iter:7000, loss:1.6805223226547241, total_2:2822, cnt_2:423, acc:2136
INFO 2024-04-17 09:43:08,078 iter:8000, loss:1.6828397512435913, total_2:2822, cnt_2:423, acc:2130
INFO 2024-04-17 10:03:18,552 iter:9000, loss:1.700141429901123, total_2:2822, cnt_2:423, acc:2145
INFO 2024-04-17 10:24:00,436 iter:10000, loss:1.7261009216308594, total_2:2822, cnt_2:423, acc:2171
INFO 2024-04-17 10:44:58,118 iter:11000, loss:1.6586881875991821, total_2:2822, cnt_2:423, acc:2141
INFO 2024-04-17 11:06:00,835 iter:12000, loss:1.6569886207580566, total_2:2822, cnt_2:423, acc:2144
INFO 2024-04-17 11:28:26,681 iter:13000, loss:1.7069528102874756, total_2:2822, cnt_2:423, acc:2102
INFO 2024-04-17 11:48:23,813 iter:14000, loss:1.6659510135650635, total_2:2822, cnt_2:423, acc:2160
INFO 2024-04-17 12:07:58,952 iter:15000, loss:1.6945695877075195, total_2:2822, cnt_2:423, acc:2171
INFO 2024-04-17 12:27:51,916 iter:16000, loss:1.6641255617141724, total_2:2822, cnt_2:423, acc:2146
INFO 2024-04-17 12:47:34,372 iter:17000, loss:1.645707130432129, total_2:2822, cnt_2:423, acc:2163
INFO 2024-04-17 12:48:41,731 train_epoch:2, total_1:0, cnt_1:0, total_2:19726, cnt_2:3376
INFO 2024-04-17 12:59:57,203 epoch:2, loss:1.6806343793869019, total_2:2822, cnt_2:423, acc:2172
INFO 2024-04-17 13:22:19,762 iter:1000, loss:1.6717394590377808, total_2:2822, cnt_2:423, acc:2156
INFO 2024-04-17 13:44:02,698 iter:2000, loss:1.678457260131836, total_2:2822, cnt_2:423, acc:2134
INFO 2024-04-17 14:05:31,812 iter:3000, loss:1.6503920555114746, total_2:2822, cnt_2:423, acc:2151
INFO 2024-04-17 14:26:46,213 iter:4000, loss:1.7597999572753906, total_2:2822, cnt_2:423, acc:2142
INFO 2024-04-17 14:48:08,994 iter:5000, loss:1.7364376783370972, total_2:2822, cnt_2:423, acc:2176
INFO 2024-04-17 15:09:41,461 iter:6000, loss:1.674788475036621, total_2:2822, cnt_2:423, acc:2140
INFO 2024-04-17 15:31:14,860 iter:7000, loss:1.7580323219299316, total_2:2822, cnt_2:423, acc:2139
INFO 2024-04-17 15:53:15,193 iter:8000, loss:1.6593737602233887, total_2:2822, cnt_2:423, acc:2110
INFO 2024-04-17 16:15:13,355 iter:9000, loss:1.6862452030181885, total_2:2822, cnt_2:423, acc:2162
INFO 2024-04-19 23:12:44,029 sss
INFO 2024-04-19 23:12:45,681 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-19 23:12:45,681 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp00sk3jaw
INFO 2024-04-19 23:12:48,795 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-19 23:12:51,125 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-19 23:12:51,125 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-19 23:15:03,337 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-19 23:15:04,872 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-19 23:15:04,911 The size of dataset: train(10492), test(2628)
INFO 2024-04-19 23:15:04,911 Start training
INFO 2024-04-19 23:33:21,547 iter:1000, loss:1.8008760213851929, total_2:2627, cnt_2:253, acc:824
INFO 2024-04-19 23:50:31,242 iter:2000, loss:1.7289378643035889, total_2:2627, cnt_2:253, acc:843
INFO 2024-04-20 00:07:57,023 iter:3000, loss:1.6523970365524292, total_2:2627, cnt_2:253, acc:876
INFO 2024-04-20 00:25:19,856 iter:4000, loss:1.6653082370758057, total_2:2627, cnt_2:253, acc:879
INFO 2024-04-20 00:42:45,031 iter:5000, loss:1.6408970355987549, total_2:2627, cnt_2:253, acc:896
INFO 2024-04-20 00:45:18,302 train_epoch:0, total_1:0, cnt_1:0, total_2:10492, cnt_2:707
INFO 2024-04-20 00:52:07,503 epoch:0, loss:1.6430844068527222, total_2:2627, cnt_2:253, acc:877
INFO 2024-04-20 01:10:37,556 iter:1000, loss:1.663914442062378, total_2:2627, cnt_2:253, acc:916
INFO 2024-04-20 01:28:04,316 iter:2000, loss:1.5978952646255493, total_2:2627, cnt_2:253, acc:922
INFO 2024-04-20 01:45:36,803 iter:3000, loss:1.6239991188049316, total_2:2627, cnt_2:253, acc:941
INFO 2024-04-20 02:03:16,171 iter:4000, loss:1.6590453386306763, total_2:2627, cnt_2:253, acc:918
INFO 2024-04-20 02:20:50,516 iter:5000, loss:1.698007345199585, total_2:2627, cnt_2:253, acc:924
INFO 2024-04-20 02:23:27,962 train_epoch:1, total_1:0, cnt_1:0, total_2:10492, cnt_2:721
INFO 2024-04-20 02:30:25,654 epoch:1, loss:1.6988160610198975, total_2:2627, cnt_2:253, acc:923
INFO 2024-04-20 02:49:17,301 iter:1000, loss:1.7587476968765259, total_2:2627, cnt_2:253, acc:945
INFO 2024-04-20 03:06:50,060 iter:2000, loss:1.8195080757141113, total_2:2627, cnt_2:253, acc:928
INFO 2024-04-20 03:24:10,886 iter:3000, loss:1.8160903453826904, total_2:2627, cnt_2:253, acc:955
INFO 2024-04-20 03:39:53,593 iter:4000, loss:1.9065814018249512, total_2:2627, cnt_2:253, acc:933
INFO 2024-04-20 03:55:23,046 iter:5000, loss:1.8497713804244995, total_2:2627, cnt_2:253, acc:930
INFO 2024-04-20 03:57:34,739 train_epoch:2, total_1:0, cnt_1:0, total_2:10492, cnt_2:727
INFO 2024-04-20 04:03:57,079 epoch:2, loss:1.902060627937317, total_2:2627, cnt_2:253, acc:948
INFO 2024-04-20 04:20:19,478 iter:1000, loss:1.8986985683441162, total_2:2627, cnt_2:253, acc:943
INFO 2024-04-20 04:35:38,692 iter:2000, loss:1.9086259603500366, total_2:2627, cnt_2:253, acc:959
INFO 2024-04-20 04:50:05,676 iter:3000, loss:1.869044542312622, total_2:2627, cnt_2:253, acc:937
INFO 2024-04-20 05:05:11,101 iter:4000, loss:1.8462790250778198, total_2:2627, cnt_2:253, acc:941
INFO 2024-04-20 05:20:20,170 iter:5000, loss:1.8510661125183105, total_2:2627, cnt_2:253, acc:953
INFO 2024-04-20 05:22:31,680 train_epoch:3, total_1:0, cnt_1:0, total_2:10492, cnt_2:692
INFO 2024-04-20 05:28:52,684 epoch:3, loss:1.879866123199463, total_2:2627, cnt_2:253, acc:960
INFO 2024-04-20 05:45:03,036 iter:1000, loss:1.8589380979537964, total_2:2627, cnt_2:253, acc:953
INFO 2024-04-20 06:00:05,577 iter:2000, loss:1.897070050239563, total_2:2627, cnt_2:253, acc:937
INFO 2024-04-20 06:15:14,448 iter:3000, loss:1.9437726736068726, total_2:2627, cnt_2:253, acc:967
INFO 2024-04-20 06:30:40,816 iter:4000, loss:1.9412708282470703, total_2:2627, cnt_2:253, acc:966
INFO 2024-04-20 06:45:58,765 iter:5000, loss:1.9775581359863281, total_2:2627, cnt_2:253, acc:934
INFO 2024-04-20 06:48:11,102 train_epoch:4, total_1:0, cnt_1:0, total_2:10492, cnt_2:708
INFO 2024-04-20 06:54:33,533 epoch:4, loss:1.9742751121520996, total_2:2627, cnt_2:253, acc:942
INFO 2024-04-20 07:11:00,813 iter:1000, loss:1.9039418697357178, total_2:2627, cnt_2:253, acc:957
INFO 2024-04-20 07:26:19,575 iter:2000, loss:1.7861297130584717, total_2:2627, cnt_2:253, acc:989
INFO 2024-04-20 07:41:30,430 iter:3000, loss:1.781982421875, total_2:2627, cnt_2:253, acc:973
INFO 2024-04-20 07:58:46,643 iter:4000, loss:1.8980653285980225, total_2:2627, cnt_2:253, acc:975
INFO 2024-04-20 08:18:37,737 iter:5000, loss:1.8764307498931885, total_2:2627, cnt_2:253, acc:963
INFO 2024-04-20 08:21:12,714 train_epoch:5, total_1:0, cnt_1:0, total_2:10492, cnt_2:699
INFO 2024-04-20 08:29:05,594 epoch:5, loss:1.8214983940124512, total_2:2627, cnt_2:253, acc:967
INFO 2024-04-20 08:49:33,758 iter:1000, loss:2.0599043369293213, total_2:2627, cnt_2:253, acc:939
INFO 2024-04-20 09:06:33,048 iter:2000, loss:1.995431900024414, total_2:2627, cnt_2:253, acc:946
INFO 2024-04-20 09:23:54,861 iter:3000, loss:1.9669498205184937, total_2:2627, cnt_2:253, acc:949
INFO 2024-04-20 09:41:14,057 iter:4000, loss:1.9512724876403809, total_2:2627, cnt_2:253, acc:953
INFO 2024-04-20 09:58:31,503 iter:5000, loss:1.8394237756729126, total_2:2627, cnt_2:253, acc:963
INFO 2024-04-20 10:01:04,504 train_epoch:6, total_1:0, cnt_1:0, total_2:10492, cnt_2:713
INFO 2024-04-20 10:07:58,650 epoch:6, loss:1.9037771224975586, total_2:2627, cnt_2:253, acc:974
INFO 2024-04-20 10:26:33,567 iter:1000, loss:1.9625940322875977, total_2:2627, cnt_2:253, acc:966
INFO 2024-04-20 10:43:40,964 iter:2000, loss:1.9874534606933594, total_2:2627, cnt_2:253, acc:974
INFO 2024-04-20 11:00:48,396 iter:3000, loss:1.814302682876587, total_2:2627, cnt_2:253, acc:996
INFO 2024-04-20 11:17:48,021 iter:4000, loss:2.0666885375976562, total_2:2627, cnt_2:253, acc:967
INFO 2024-04-20 11:34:55,899 iter:5000, loss:2.056820869445801, total_2:2627, cnt_2:253, acc:964
INFO 2024-04-20 11:37:24,880 train_epoch:7, total_1:0, cnt_1:0, total_2:10492, cnt_2:716
INFO 2024-04-20 11:44:03,928 epoch:7, loss:1.9520412683486938, total_2:2627, cnt_2:253, acc:951
INFO 2024-04-20 12:03:40,282 iter:1000, loss:1.943647861480713, total_2:2627, cnt_2:253, acc:966
INFO 2024-04-20 12:21:16,219 iter:2000, loss:2.111194133758545, total_2:2627, cnt_2:253, acc:937
INFO 2024-04-20 12:40:08,420 iter:3000, loss:2.009117364883423, total_2:2627, cnt_2:253, acc:975
INFO 2024-04-20 12:58:51,208 iter:4000, loss:1.9626350402832031, total_2:2627, cnt_2:253, acc:970
INFO 2024-04-20 13:17:37,346 iter:5000, loss:1.9642601013183594, total_2:2627, cnt_2:253, acc:973
INFO 2024-04-20 13:20:27,875 train_epoch:8, total_1:0, cnt_1:0, total_2:10492, cnt_2:726
INFO 2024-04-20 13:31:10,029 epoch:8, loss:2.027594566345215, total_2:2627, cnt_2:253, acc:982
INFO 2024-04-20 13:54:49,392 iter:1000, loss:2.1059892177581787, total_2:2627, cnt_2:253, acc:971
INFO 2024-04-20 14:11:39,654 iter:2000, loss:2.0995607376098633, total_2:2627, cnt_2:253, acc:971
INFO 2024-04-20 14:28:25,558 iter:3000, loss:2.1124398708343506, total_2:2627, cnt_2:253, acc:983
INFO 2024-04-20 14:44:28,000 iter:4000, loss:2.0105390548706055, total_2:2627, cnt_2:253, acc:958
INFO 2024-04-20 15:01:16,963 iter:5000, loss:2.1347358226776123, total_2:2627, cnt_2:253, acc:956
INFO 2024-04-20 15:03:45,344 train_epoch:9, total_1:0, cnt_1:0, total_2:10492, cnt_2:715
INFO 2024-04-20 15:10:27,434 epoch:9, loss:2.1151623725891113, total_2:2627, cnt_2:253, acc:964
INFO 2024-04-20 15:28:35,299 iter:1000, loss:1.8663463592529297, total_2:2627, cnt_2:253, acc:973
INFO 2024-04-20 15:33:21,853 sss
INFO 2024-04-20 15:33:23,848 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-20 15:33:23,849 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmptmc8ww7z
INFO 2024-04-20 15:33:27,163 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}


INFO 2024-04-20 15:40:25,527 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-20 15:40:25,527 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-20 15:42:37,668 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-20 15:42:39,131 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-20 15:42:39,170 The size of dataset: train(10492), test(2628)
INFO 2024-04-20 15:42:39,170 Start training
INFO 2024-04-20 16:00:23,121 iter:1000, loss:1.7979702949523926, total_2:1694, cnt_2:185, acc:836
INFO 2024-04-20 16:17:26,866 iter:2000, loss:1.7257167100906372, total_2:1694, cnt_2:185, acc:833
INFO 2024-04-20 16:34:40,169 iter:3000, loss:1.6510071754455566, total_2:1694, cnt_2:185, acc:853
INFO 2024-04-20 16:51:55,686 iter:4000, loss:1.638734221458435, total_2:1694, cnt_2:185, acc:874
INFO 2024-04-20 17:09:17,753 iter:5000, loss:1.614330768585205, total_2:1694, cnt_2:185, acc:893
INFO 2024-04-20 17:11:50,554 train_epoch:0, total_1:0, cnt_1:0, total_2:8131, cnt_2:603
INFO 2024-04-20 17:18:26,805 epoch:0, loss:1.6718933582305908, total_2:1694, cnt_2:185, acc:872
INFO 2024-04-20 17:36:42,650 iter:1000, loss:1.6449187994003296, total_2:1694, cnt_2:185, acc:911
INFO 2024-04-20 17:54:50,147 iter:2000, loss:1.6513437032699585, total_2:1694, cnt_2:185, acc:935
INFO 2024-04-20 18:12:00,612 iter:3000, loss:1.632657766342163, total_2:1694, cnt_2:185, acc:927
INFO 2024-04-20 18:30:26,863 iter:4000, loss:1.768332600593567, total_2:1694, cnt_2:185, acc:898
INFO 2024-04-20 18:51:25,948 iter:5000, loss:1.6479249000549316, total_2:1694, cnt_2:185, acc:959
INFO 2024-04-20 18:54:11,306 train_epoch:1, total_1:0, cnt_1:0, total_2:8121, cnt_2:591
INFO 2024-04-20 19:01:06,630 epoch:1, loss:1.6806321144104004, total_2:1694, cnt_2:185, acc:925
INFO 2024-04-20 19:23:02,012 iter:1000, loss:1.7418162822723389, total_2:1694, cnt_2:185, acc:928
INFO 2024-04-20 19:44:08,952 iter:2000, loss:1.8394055366516113, total_2:1694, cnt_2:185, acc:942
INFO 2024-04-20 20:01:30,693 iter:3000, loss:1.8462680578231812, total_2:1694, cnt_2:185, acc:938
INFO 2024-04-20 20:18:42,418 iter:4000, loss:1.8795405626296997, total_2:1694, cnt_2:185, acc:916
INFO 2024-04-20 20:39:22,145 iter:5000, loss:1.7834926843643188, total_2:1694, cnt_2:185, acc:938
INFO 2024-04-20 20:41:54,074 train_epoch:2, total_1:0, cnt_1:0, total_2:8116, cnt_2:596
INFO 2024-04-20 20:48:43,858 epoch:2, loss:1.8533282279968262, total_2:1694, cnt_2:185, acc:931
INFO 2024-04-20 21:06:24,475 iter:1000, loss:1.89736008644104, total_2:1694, cnt_2:185, acc:959
INFO 2024-04-20 21:23:33,612 iter:2000, loss:1.8028924465179443, total_2:1694, cnt_2:185, acc:983
INFO 2024-04-20 21:40:46,373 iter:3000, loss:1.8244447708129883, total_2:1694, cnt_2:185, acc:989
INFO 2024-04-20 21:58:04,074 iter:4000, loss:1.8497036695480347, total_2:1694, cnt_2:185, acc:963
INFO 2024-04-20 22:15:07,288 iter:5000, loss:1.8583641052246094, total_2:1694, cnt_2:185, acc:950
INFO 2024-04-20 22:17:37,221 train_epoch:3, total_1:0, cnt_1:0, total_2:8119, cnt_2:616
INFO 2024-04-20 22:23:57,773 epoch:3, loss:1.9050512313842773, total_2:1694, cnt_2:185, acc:965
INFO 2024-04-20 22:47:14,644 iter:1000, loss:1.8821684122085571, total_2:1694, cnt_2:185, acc:944
INFO 2024-04-20 23:06:16,819 iter:2000, loss:1.938209056854248, total_2:1694, cnt_2:185, acc:966
INFO 2024-04-20 23:26:13,488 iter:3000, loss:1.9725230932235718, total_2:1694, cnt_2:185, acc:970
INFO 2024-04-20 23:43:51,651 iter:4000, loss:1.9082424640655518, total_2:1694, cnt_2:185, acc:977
INFO 2024-04-21 00:01:07,255 iter:5000, loss:1.8441754579544067, total_2:1694, cnt_2:185, acc:984
INFO 2024-04-21 00:03:40,911 train_epoch:4, total_1:0, cnt_1:0, total_2:8133, cnt_2:610
INFO 2024-04-21 00:10:31,138 epoch:4, loss:1.8867543935775757, total_2:1694, cnt_2:185, acc:992
INFO 2024-04-21 00:28:43,859 iter:1000, loss:1.948337435722351, total_2:1694, cnt_2:185, acc:957
INFO 2024-04-21 00:45:37,575 iter:2000, loss:2.0537657737731934, total_2:1694, cnt_2:185, acc:961
INFO 2024-04-21 01:02:38,274 iter:3000, loss:1.8567148447036743, total_2:1694, cnt_2:185, acc:970
INFO 2024-04-21 01:20:37,383 iter:4000, loss:1.9257732629776, total_2:1694, cnt_2:185, acc:940
INFO 2024-04-21 01:37:59,524 iter:5000, loss:1.9206346273422241, total_2:1694, cnt_2:185, acc:963
INFO 2024-04-21 01:40:29,514 train_epoch:5, total_1:0, cnt_1:0, total_2:8114, cnt_2:601
INFO 2024-04-21 01:47:18,240 epoch:5, loss:1.9674996137619019, total_2:1694, cnt_2:185, acc:962
INFO 2024-04-21 02:05:13,031 iter:1000, loss:1.9137213230133057, total_2:1694, cnt_2:185, acc:957
INFO 2024-04-21 02:22:26,537 iter:2000, loss:1.7694964408874512, total_2:1694, cnt_2:185, acc:976
INFO 2024-04-21 02:42:06,314 iter:3000, loss:1.8789782524108887, total_2:1694, cnt_2:185, acc:975
INFO 2024-04-21 03:02:08,864 iter:4000, loss:1.9497854709625244, total_2:1694, cnt_2:185, acc:989
INFO 2024-04-21 03:20:33,996 iter:5000, loss:1.893494963645935, total_2:1694, cnt_2:185, acc:972
INFO 2024-04-21 03:23:40,103 train_epoch:6, total_1:0, cnt_1:0, total_2:8114, cnt_2:608
INFO 2024-04-21 03:31:01,426 epoch:6, loss:1.8626482486724854, total_2:1694, cnt_2:185, acc:968
INFO 2024-04-21 03:49:22,129 iter:1000, loss:2.0000507831573486, total_2:1694, cnt_2:185, acc:988
INFO 2024-04-21 04:06:28,774 iter:2000, loss:1.9134440422058105, total_2:1694, cnt_2:185, acc:981
INFO 2024-04-21 04:23:39,226 iter:3000, loss:1.8386650085449219, total_2:1694, cnt_2:185, acc:986
INFO 2024-04-21 04:40:44,975 iter:4000, loss:2.0665431022644043, total_2:1694, cnt_2:185, acc:957
INFO 2024-04-21 04:59:56,402 iter:5000, loss:2.006613254547119, total_2:1694, cnt_2:185, acc:970
INFO 2024-04-21 05:02:43,067 train_epoch:7, total_1:0, cnt_1:0, total_2:8133, cnt_2:613
INFO 2024-04-21 05:09:40,047 epoch:7, loss:1.8846079111099243, total_2:1694, cnt_2:185, acc:963
INFO 2024-04-21 05:27:43,477 iter:1000, loss:1.9390095472335815, total_2:1694, cnt_2:185, acc:960
INFO 2024-04-21 05:44:59,716 iter:2000, loss:1.9150424003601074, total_2:1694, cnt_2:185, acc:993
INFO 2024-04-21 06:01:38,135 iter:3000, loss:1.9539577960968018, total_2:1694, cnt_2:185, acc:1005
INFO 2024-04-21 06:17:10,468 iter:4000, loss:2.1087429523468018, total_2:1694, cnt_2:185, acc:952
INFO 2024-04-21 06:32:24,875 iter:5000, loss:1.9663022756576538, total_2:1694, cnt_2:185, acc:947
INFO 2024-04-21 06:34:33,226 train_epoch:8, total_1:0, cnt_1:0, total_2:8125, cnt_2:599
INFO 2024-04-21 06:40:46,878 epoch:8, loss:1.9489198923110962, total_2:1694, cnt_2:185, acc:953
INFO 2024-04-21 06:56:50,855 iter:1000, loss:2.037928342819214, total_2:1694, cnt_2:185, acc:962
INFO 2024-04-21 07:11:57,083 iter:2000, loss:2.1061012744903564, total_2:1694, cnt_2:185, acc:953
INFO 2024-04-21 07:26:52,399 iter:3000, loss:2.145134210586548, total_2:1694, cnt_2:185, acc:962
INFO 2024-04-21 07:41:53,647 iter:4000, loss:2.2692911624908447, total_2:1694, cnt_2:185, acc:942
INFO 2024-04-21 07:56:45,543 iter:5000, loss:2.1445086002349854, total_2:1694, cnt_2:185, acc:950
INFO 2024-04-21 07:58:54,076 train_epoch:9, total_1:0, cnt_1:0, total_2:8117, cnt_2:604
INFO 2024-04-21 08:05:04,513 epoch:9, loss:2.1823344230651855, total_2:1694, cnt_2:185, acc:947
INFO 2024-04-21 08:21:03,136 iter:1000, loss:2.1526336669921875, total_2:1694, cnt_2:185, acc:962
INFO 2024-04-21 08:37:25,325 iter:2000, loss:2.054976463317871, total_2:1694, cnt_2:185, acc:986
INFO 2024-04-21 08:54:25,893 iter:3000, loss:2.0994009971618652, total_2:1694, cnt_2:185, acc:987
INFO 2024-04-21 09:11:42,812 iter:4000, loss:2.0081582069396973, total_2:1694, cnt_2:185, acc:985
INFO 2024-04-21 09:33:22,653 iter:5000, loss:1.908442497253418, total_2:1694, cnt_2:185, acc:960
INFO 2024-04-21 09:36:28,533 train_epoch:10, total_1:0, cnt_1:0, total_2:8133, cnt_2:592
INFO 2024-04-21 09:43:18,131 epoch:10, loss:2.0188956260681152, total_2:1694, cnt_2:185, acc:963
INFO 2024-04-21 10:04:11,885 iter:1000, loss:2.0728166103363037, total_2:1694, cnt_2:185, acc:953
INFO 2024-04-21 10:23:23,825 iter:2000, loss:2.015023708343506, total_2:1694, cnt_2:185, acc:959
INFO 2024-04-21 10:41:37,305 iter:3000, loss:2.0603384971618652, total_2:1694, cnt_2:185, acc:971
INFO 2024-04-21 10:58:49,673 iter:4000, loss:2.014185667037964, total_2:1694, cnt_2:185, acc:979
INFO 2024-04-21 11:16:47,521 iter:5000, loss:2.009159803390503, total_2:1694, cnt_2:185, acc:983
INFO 2024-04-21 11:19:28,349 train_epoch:11, total_1:0, cnt_1:0, total_2:8119, cnt_2:611
INFO 2024-04-21 11:26:23,365 epoch:11, loss:1.9199079275131226, total_2:1694, cnt_2:185, acc:981
INFO 2024-04-21 11:36:27,556 sss
INFO 2024-04-21 11:36:28,986 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-21 11:36:28,987 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpfzjhaph0
INFO 2024-04-21 11:36:31,864 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

INFO 2024-04-21 11:36:46,116 The num of learnable parameters: backbone(23232512), vis_enc(8414976), bert(108891648), freeze(728451, rest(789504)
INFO 2024-04-21 11:36:46,117 Check the whole parameters: 142057091 = 142057091
INFO 2024-04-21 11:38:58,304 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-21 11:38:59,715 loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/yanruxue/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
INFO 2024-04-21 11:38:59,748 The size of dataset: train(10492), test(2628)
INFO 2024-04-21 11:38:59,749 Start training
INFO 2024-04-21 11:51:29,953 iter:1000, loss:1.8110253810882568, total_2:2010, cnt_2:199, acc:837
INFO 2024-04-21 12:02:40,427 iter:2000, loss:1.7242070436477661, total_2:2010, cnt_2:199, acc:841
INFO 2024-04-21 12:14:22,046 iter:3000, loss:1.722584843635559, total_2:2010, cnt_2:199, acc:887
INFO 2024-04-21 12:25:40,014 iter:4000, loss:1.6723911762237549, total_2:2010, cnt_2:199, acc:877
INFO 2024-04-21 12:37:12,918 iter:5000, loss:1.627119541168213, total_2:2010, cnt_2:199, acc:921
INFO 2024-04-21 12:38:43,047 train_epoch:0, total_1:0, cnt_1:0, total_2:9037, cnt_2:851
INFO 2024-04-21 12:43:51,035 epoch:0, loss:1.6492708921432495, total_2:2010, cnt_2:199, acc:886
INFO 2024-04-21 12:56:04,684 iter:1000, loss:1.6349126100540161, total_2:2010, cnt_2:199, acc:915
INFO 2024-04-21 13:07:12,794 iter:2000, loss:1.6527496576309204, total_2:2010, cnt_2:199, acc:915
INFO 2024-04-21 13:18:30,276 iter:3000, loss:1.5771044492721558, total_2:2010, cnt_2:199, acc:939
INFO 2024-04-21 13:29:45,393 iter:4000, loss:1.7649215459823608, total_2:2010, cnt_2:199, acc:922
INFO 2024-04-21 13:40:57,912 iter:5000, loss:1.6824086904525757, total_2:2010, cnt_2:199, acc:947
INFO 2024-04-21 13:42:10,794 train_epoch:1, total_1:0, cnt_1:0, total_2:9062, cnt_2:842
INFO 2024-04-21 13:47:03,965 epoch:1, loss:1.7168039083480835, total_2:2010, cnt_2:199, acc:927
INFO 2024-04-21 13:58:01,643 iter:1000, loss:1.7674363851547241, total_2:2010, cnt_2:199, acc:941
INFO 2024-04-21 14:07:50,689 iter:2000, loss:1.783631682395935, total_2:2010, cnt_2:199, acc:950
INFO 2024-04-21 14:17:37,942 iter:3000, loss:1.8065259456634521, total_2:2010, cnt_2:199, acc:983
INFO 2024-04-21 14:27:42,825 iter:4000, loss:1.8883105516433716, total_2:2010, cnt_2:199, acc:945
INFO 2024-04-21 14:37:48,124 iter:5000, loss:1.7943344116210938, total_2:2010, cnt_2:199, acc:938
INFO 2024-04-21 14:39:02,480 train_epoch:2, total_1:0, cnt_1:0, total_2:9053, cnt_2:853
INFO 2024-04-21 14:43:57,907 epoch:2, loss:1.9503196477890015, total_2:2010, cnt_2:199, acc:942
INFO 2024-04-21 14:54:47,283 iter:1000, loss:1.9266533851623535, total_2:2010, cnt_2:199, acc:941
INFO 2024-04-21 15:04:47,422 iter:2000, loss:1.7533748149871826, total_2:2010, cnt_2:199, acc:970
INFO 2024-04-21 15:14:51,377 iter:3000, loss:1.8230681419372559, total_2:2010, cnt_2:199, acc:983
INFO 2024-04-21 15:24:42,489 iter:4000, loss:1.9507583379745483, total_2:2010, cnt_2:199, acc:930
INFO 2024-04-21 15:34:31,537 iter:5000, loss:1.9233968257904053, total_2:2010, cnt_2:199, acc:936
INFO 2024-04-21 15:35:44,157 train_epoch:3, total_1:0, cnt_1:0, total_2:9056, cnt_2:833
INFO 2024-04-21 15:40:42,116 epoch:3, loss:1.9709908962249756, total_2:2010, cnt_2:199, acc:946
INFO 2024-04-21 15:51:31,568 iter:1000, loss:1.9034439325332642, total_2:2010, cnt_2:199, acc:950
INFO 2024-04-21 16:01:30,015 iter:2000, loss:1.8915650844573975, total_2:2010, cnt_2:199, acc:975
INFO 2024-04-21 16:11:26,927 iter:3000, loss:1.867142677307129, total_2:2010, cnt_2:199, acc:983
INFO 2024-04-21 16:21:21,033 iter:4000, loss:1.8767290115356445, total_2:2010, cnt_2:199, acc:966
INFO 2024-04-21 16:31:14,642 iter:5000, loss:1.7896313667297363, total_2:2010, cnt_2:199, acc:966
INFO 2024-04-21 16:32:28,714 train_epoch:4, total_1:0, cnt_1:0, total_2:9050, cnt_2:840
INFO 2024-04-21 16:37:23,119 epoch:4, loss:1.8154572248458862, total_2:2010, cnt_2:199, acc:948
INFO 2024-04-21 16:48:12,331 iter:1000, loss:1.8463810682296753, total_2:2010, cnt_2:199, acc:977
INFO 2024-04-21 16:58:02,673 iter:2000, loss:1.8750829696655273, total_2:2010, cnt_2:199, acc:959
INFO 2024-04-21 17:07:46,543 iter:3000, loss:1.872166633605957, total_2:2010, cnt_2:199, acc:962
INFO 2024-04-21 17:17:39,717 iter:4000, loss:1.8802669048309326, total_2:2010, cnt_2:199, acc:964
INFO 2024-04-21 17:27:33,284 iter:5000, loss:1.8712317943572998, total_2:2010, cnt_2:199, acc:937
INFO 2024-04-21 17:28:46,112 train_epoch:5, total_1:0, cnt_1:0, total_2:9055, cnt_2:837
INFO 2024-04-21 17:33:46,224 epoch:5, loss:1.9144707918167114, total_2:2010, cnt_2:199, acc:952
INFO 2024-04-21 17:44:37,407 iter:1000, loss:2.0144388675689697, total_2:2010, cnt_2:199, acc:957
INFO 2024-04-21 17:54:25,393 iter:2000, loss:2.0415878295898438, total_2:2010, cnt_2:199, acc:949
INFO 2024-04-21 18:04:17,766 iter:3000, loss:1.8749749660491943, total_2:2010, cnt_2:199, acc:964
INFO 2024-04-21 18:14:15,249 iter:4000, loss:2.0290725231170654, total_2:2010, cnt_2:199, acc:950
INFO 2024-04-21 18:16:59,580 sss
INFO 2024-04-21 18:17:00,746 loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
INFO 2024-04-21 18:17:00,747 extracting archive file /home/yanruxue/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmphrsdh9my
INFO 2024-04-21 18:17:03,438 Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

